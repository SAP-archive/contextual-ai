

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Model Interpreter via XAI &mdash; XAI  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="model package" href="../../model/model.html" />
    <link rel="prev" title="XAI Model tutorials" href="../../training_module_tutorial.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> XAI
          

          
          </a>

          
            
            
              <div class="version">
                0.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">XAI Documentation</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../data_module.html">Data Module</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../training_module.html">Model Module</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../training_module_tutorial.html">Tutorial</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../training_module_tutorial.html#model-interpreter">Model interpreter</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="../../training_module_tutorial.html#tutorial">Tutorial</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../model/model.html">API Documentation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../inference_module.html">Explainer Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../formatter_module.html">Formatter Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compiler_module.html">Compiler Module</a></li>
</ul>
<p class="caption"><span class="caption-text">Miscellaneous</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer_guide.html">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autodoc.html">XAI Auto-doc</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">XAI</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../training_module.html">Model Module</a> &raquo;</li>
        
          <li><a href="../../training_module_tutorial.html">XAI Model tutorials</a> &raquo;</li>
        
      <li>Model Interpreter via XAI</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/tutorials/model_interpreter/tutorial_model_interpreter.nblink.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Model-Interpreter-via-XAI">
<h1>Model Interpreter via XAI<a class="headerlink" href="#Model-Interpreter-via-XAI" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we use <code class="docutils literal notranslate"><span class="pre">xai</span></code> to analyze a trained model and its features. The tutorial contains 3 parts: - feature distribution analysis - trained model feature importance analysis - model interpretation via explanation aggregation</p>
<div class="section" id="Prerequisites-:-Import-libraries">
<h2>Prerequisites : Import libraries<a class="headerlink" href="#Prerequisites-:-Import-libraries" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">xai.model.interpreter</span></code> is the main package that users of XAI interact with.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Some auxiliary imports for the tutorial</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="c1"># Set seed for reproducibility</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123456</span><span class="p">)</span>

<span class="c1"># Set the path so that we can import ExplainerFactory</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;../../&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Main XAI imports</span>
<span class="kn">import</span> <span class="nn">xai</span>
<span class="kn">from</span> <span class="nn">xai.model.interpreter.model_interpreter</span> <span class="kn">import</span> <span class="n">ModelInterpreter</span>
</pre></div>
</div>
</div>
<p>In this tutorial, we train a sample <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code> model on the Wisconsin breast cancer dataset, a sample binary classification problem that is provided by scikit-learn (details can be found <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer">here</a>). We will use APIs in <code class="docutils literal notranslate"><span class="pre">xai.model_interpreter</span></code> package to conduct feature analysis, feature ranking and model interpretation.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Load the dataset and prepare training and test sets</span>
<span class="n">raw_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_breast_cancer</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">raw_data</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">],</span> <span class="n">raw_data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="1.-Feature-Analysis">
<h2>1. Feature Analysis<a class="headerlink" href="#1.-Feature-Analysis" title="Permalink to this headline">¶</a></h2>
<p>Key parameters used in feature analysis: - feature_names: a list of str, names of each feature. - feature_types: a list of str, pre-defined type for each feature. - train_x: numpy.dnarray, training data. Each row is a training sample, each column is a feature. - labels: a list of str/int, the class label for each training sample. - trained_model: model object, the trained model object.</p>
<div class="section" id="Feature-Distribution">
<h3>Feature Distribution<a class="headerlink" href="#Feature-Distribution" title="Permalink to this headline">¶</a></h3>
<p>To analyze the feature distribution, we need to import <code class="docutils literal notranslate"><span class="pre">xai.model_interpreter.FeatureInterpreter</span></code> to initialize a <code class="docutils literal notranslate"><span class="pre">FeatureInterpreter</span></code> and call the <code class="docutils literal notranslate"><span class="pre">get_feature_distribution()</span></code> function.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Define the feature data type and feature names</span>
<span class="kn">from</span> <span class="nn">xai.data.constants</span> <span class="kn">import</span> <span class="n">DATATYPE</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">raw_data</span><span class="p">[</span><span class="s1">&#39;feature_names&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">feature_types</span> <span class="o">=</span> <span class="p">[</span><span class="n">DATATYPE</span><span class="o">.</span><span class="n">NUMBER</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">feature_names</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">xai.model.interpreter.feature_interpreter</span> <span class="kn">import</span> <span class="n">FeatureInterpreter</span>
<span class="n">feature_interpreter</span> <span class="o">=</span> <span class="n">FeatureInterpreter</span><span class="p">(</span><span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>

<span class="n">stats</span> <span class="o">=</span> <span class="n">feature_interpreter</span><span class="o">.</span><span class="n">get_feature_distribution</span><span class="p">(</span><span class="n">feature_types</span><span class="o">=</span><span class="n">feature_types</span><span class="p">,</span><span class="n">train_x</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We use our plot helper class <code class="docutils literal notranslate"><span class="pre">NotebookPlots</span></code> to plot the feature distribution results for the first 3 features. Details for each type of stats can be found in <code class="docutils literal notranslate"><span class="pre">xai.data.explorer</span></code> under different data type packages.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">xai.plots.data_stats_notebook_plots</span> <span class="kn">import</span> <span class="n">NotebookPlots</span>
<span class="n">plotter</span> <span class="o">=</span> <span class="n">NotebookPlots</span><span class="p">()</span>

<span class="n">sample_features</span> <span class="o">=</span> <span class="n">feature_names</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
<span class="k">for</span> <span class="n">feature_name</span> <span class="ow">in</span> <span class="n">sample_features</span><span class="p">:</span>
    <span class="p">(</span><span class="n">label_feature_stats</span><span class="p">,</span> <span class="n">all_feature_stats</span><span class="p">)</span> <span class="o">=</span> <span class="n">stats</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span>

    <span class="n">plotter</span><span class="o">.</span><span class="n">plot_labelled_numerical_stats</span><span class="p">(</span><span class="n">labelled_stats</span><span class="o">=</span><span class="n">label_feature_stats</span><span class="p">,</span> <span class="c1"># stats for each class</span>
                                          <span class="n">all_stats</span><span class="o">=</span><span class="n">all_feature_stats</span><span class="p">,</span> <span class="c1"># stats for all classes</span>
                                          <span class="n">label_column</span><span class="o">=</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span> <span class="c1"># column name for label</span>
                                          <span class="n">feature_column</span><span class="o">=</span><span class="n">feature_name</span><span class="p">)</span> <span class="c1"># column name for feature</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="section" id="mean-radius">
<h4>mean radius<a class="headerlink" href="#mean-radius" title="Permalink to this headline">¶</a></h4>
</div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_9_1.png" src="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_9_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>class</th>
      <th>min</th>
      <th>max</th>
      <th>mean</th>
      <th>median</th>
      <th>sd</th>
      <th>total_count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>6.981</td>
      <td>16.84</td>
      <td>12.095455</td>
      <td>1.700759</td>
      <td>16.84</td>
      <td>286</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>11.420</td>
      <td>28.11</td>
      <td>17.468462</td>
      <td>3.158721</td>
      <td>28.11</td>
      <td>169</td>
    </tr>
    <tr>
      <th>2</th>
      <td>all</td>
      <td>6.981</td>
      <td>28.11</td>
      <td>14.091143</td>
      <td>3.502028</td>
      <td>28.11</td>
      <td>455</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="section" id="mean-texture">
<h4>mean texture<a class="headerlink" href="#mean-texture" title="Permalink to this headline">¶</a></h4>
</div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_9_4.png" src="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_9_4.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>class</th>
      <th>min</th>
      <th>max</th>
      <th>mean</th>
      <th>median</th>
      <th>sd</th>
      <th>total_count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>9.71</td>
      <td>33.81</td>
      <td>18.066643</td>
      <td>4.013245</td>
      <td>33.81</td>
      <td>286</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>10.38</td>
      <td>39.28</td>
      <td>21.600118</td>
      <td>3.738992</td>
      <td>39.28</td>
      <td>169</td>
    </tr>
    <tr>
      <th>2</th>
      <td>all</td>
      <td>9.71</td>
      <td>39.28</td>
      <td>19.379077</td>
      <td>4.269827</td>
      <td>39.28</td>
      <td>455</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="section" id="mean-perimeter">
<h4>mean perimeter<a class="headerlink" href="#mean-perimeter" title="Permalink to this headline">¶</a></h4>
</div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_9_7.png" src="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_9_7.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>class</th>
      <th>min</th>
      <th>max</th>
      <th>mean</th>
      <th>median</th>
      <th>sd</th>
      <th>total_count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>43.79</td>
      <td>108.4</td>
      <td>77.730105</td>
      <td>11.292902</td>
      <td>108.4</td>
      <td>286</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>75.00</td>
      <td>188.5</td>
      <td>115.335503</td>
      <td>21.653977</td>
      <td>188.5</td>
      <td>169</td>
    </tr>
    <tr>
      <th>2</th>
      <td>all</td>
      <td>43.79</td>
      <td>188.5</td>
      <td>91.697824</td>
      <td>24.176163</td>
      <td>188.5</td>
      <td>455</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
<div class="section" id="Feature-correlation">
<h3>Feature correlation<a class="headerlink" href="#Feature-correlation" title="Permalink to this headline">¶</a></h3>
<p>To analyze the feature correlction, we need to import <code class="docutils literal notranslate"><span class="pre">xai.model_interpreter.FeatureInterpreter</span></code> to initialize a <code class="docutils literal notranslate"><span class="pre">FeatureInterpreter</span></code> and call the <code class="docutils literal notranslate"><span class="pre">get_feature_correlation()</span></code> function. Same <code class="docutils literal notranslate"><span class="pre">FeatureInterpreter</span></code> object can be reused here for correlation analysis.</p>
<p>In this sample, as all the features are numerical features, correlation are calculated using Pearson’s testing as a default setup. And we use plot helper function to plot the heatmap for the correlation between all features.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">types</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="n">feature_interpreter</span><span class="o">.</span><span class="n">get_feature_correlation</span><span class="p">(</span><span class="n">feature_types</span><span class="o">=</span><span class="n">feature_types</span><span class="p">,</span><span class="n">train_x</span><span class="o">=</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">plotter</span><span class="o">.</span><span class="n">plot_correlation_heatmap</span><span class="p">(</span><span class="n">types</span><span class="p">,</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
../../xai/model/interpreter/feature_interpreter.py:138: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  correlation_types[col1][col2] = method
/Users/i309943/opt/anaconda3/envs/xai/lib/python3.6/site-packages/pandas/core/indexing.py:202: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  self._setitem_with_indexer(indexer, value)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="section" id="Correlation-Type:-pearson">
<h4>Correlation Type: pearson<a class="headerlink" href="#Correlation-Type:-pearson" title="Permalink to this headline">¶</a></h4>
</div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_11_2.png" src="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_11_2.png" />
</div>
</div>
</div>
</div>
<div class="section" id="2.-Feature-Importance">
<h2>2. Feature Importance<a class="headerlink" href="#2.-Feature-Importance" title="Permalink to this headline">¶</a></h2>
<p>As feature importance is associated with a model, we need to firstly train a sample model first. In this tutorial, we train a sample <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code> model on the the dataset.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Instantiate a classifier, train, and evaluate on test set</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/Users/i309943/opt/anaconda3/envs/xai/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
  &#34;10 in version 0.20 to 100 in 0.22.&#34;, FutureWarning)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.956140350877193
</pre></div>
</div>
</div>
<p>To analysze the feature importance ranking, we need to import <code class="docutils literal notranslate"><span class="pre">xai.model_interpreter.FeatureInterpreter</span></code> to initialize a <code class="docutils literal notranslate"><span class="pre">FeatureInterpreter</span></code> and call the <code class="docutils literal notranslate"><span class="pre">get_feature_ranking()</span></code> function. Same <code class="docutils literal notranslate"><span class="pre">FeatureInterpreter</span></code> object can be reused here for feature importance ranking.</p>
<p>The code below shows the feature importance used the default method provided by the model itself.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">feature_importance_ranking</span> <span class="o">=</span> <span class="n">feature_interpreter</span><span class="o">.</span><span class="n">get_feature_importance_ranking</span><span class="p">(</span><span class="n">trained_model</span><span class="o">=</span><span class="n">clf</span><span class="p">,</span>
                                                                                <span class="n">train_x</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span>
                                                                                <span class="n">method</span><span class="o">=</span><span class="s1">&#39;default&#39;</span><span class="p">)</span>
<span class="n">plotter</span><span class="o">.</span><span class="n">plot_feature_importance_ranking</span><span class="p">(</span><span class="n">feature_importance_ranking</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_15_0.png" src="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_15_0.png" />
</div>
</div>
<p>By changing the method, we can get feature importance based on different criterion. The code below shows the feature importance calculated by shap value.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">feature_importance_ranking</span> <span class="o">=</span> <span class="n">feature_interpreter</span><span class="o">.</span><span class="n">get_feature_importance_ranking</span><span class="p">(</span><span class="n">trained_model</span><span class="o">=</span><span class="n">clf</span><span class="p">,</span>
                                                                                <span class="n">train_x</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span>
                                                                                <span class="n">method</span><span class="o">=</span><span class="s1">&#39;shap&#39;</span><span class="p">)</span>
<span class="n">plotter</span><span class="o">.</span><span class="n">plot_feature_importance_ranking</span><span class="p">(</span><span class="n">feature_importance_ranking</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_17_0.png" src="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_17_0.png" />
</div>
</div>
<p>We can also plot the shap values in a summary plot to show individual sample shap values for all the features.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">feature_shap_values</span> <span class="o">=</span> <span class="n">feature_interpreter</span><span class="o">.</span><span class="n">get_feature_shap_values</span><span class="p">(</span><span class="n">trained_model</span><span class="o">=</span><span class="n">clf</span><span class="p">,</span>
                                                                  <span class="n">train_x</span><span class="o">=</span><span class="n">X_train</span><span class="p">)</span>

<span class="n">plotter</span><span class="o">.</span><span class="n">plot_feature_shap_values</span><span class="p">(</span><span class="n">feature_shap_values</span><span class="p">,</span><span class="n">class_id</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X_train</span><span class="o">=</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_19_0.png" src="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_19_0.png" />
</div>
</div>
</div>
<div class="section" id="3.-Model-Interpretation-by-aggregate-explanations">
<h2>3. Model Interpretation by aggregate explanations<a class="headerlink" href="#3.-Model-Interpretation-by-aggregate-explanations" title="Permalink to this headline">¶</a></h2>
<p>One way to interpret the model is by aggregating the individual explanations which tries to explain the model locally</p>
<div class="section" id="Step-0.-Import-the-ModelInterpreter">
<h3>Step 0. Import the <code class="docutils literal notranslate"><span class="pre">ModelInterpreter</span></code><a class="headerlink" href="#Step-0.-Import-the-ModelInterpreter" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">xai.model.interpreter.model_interpreter</span> <span class="kn">import</span> <span class="n">ModelInterpreter</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Step-1.-Define-domain-and-algorithm">
<h3>Step 1. Define domain and algorithm<a class="headerlink" href="#Step-1.-Define-domain-and-algorithm" title="Permalink to this headline">¶</a></h3>
<p>As model interpreter is using a model-agnostic explainer, domain and algorithm is dependent on <code class="docutils literal notranslate"><span class="pre">xai.explainer</span></code> package. See details in <code class="docutils literal notranslate"><span class="pre">xai.explainer.config</span></code></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">xai.explainer.config</span> <span class="kn">import</span> <span class="n">DOMAIN</span><span class="p">,</span> <span class="n">ALG</span>
<span class="n">model_interpreter</span> <span class="o">=</span> <span class="n">ModelInterpreter</span><span class="p">(</span><span class="n">domain</span><span class="o">=</span><span class="n">DOMAIN</span><span class="o">.</span><span class="n">TABULAR</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">ALG</span><span class="o">.</span><span class="n">LIME</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Step-2.-Build-interpreter">
<h3>Step 2. Build interpreter<a class="headerlink" href="#Step-2.-Build-interpreter" title="Permalink to this headline">¶</a></h3>
<p>Based on the domain and algorithm chosen, build the explainer in the interpreter by passing in the required parameter.</p>
<p>Required parameters include: - training data - training labels - model prediction functions</p>
<p>See details in <code class="docutils literal notranslate"><span class="pre">xai.explainer</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model_interpreter</span><span class="o">.</span><span class="n">build_interpreter</span><span class="p">(</span>
    <span class="n">training_data</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span>
    <span class="n">training_labels</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="n">xai</span><span class="o">.</span><span class="n">MODE</span><span class="o">.</span><span class="n">CLASSIFICATION</span><span class="p">,</span>
    <span class="n">predict_fn</span><span class="o">=</span><span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">,</span>
    <span class="n">feature_names</span><span class="o">=</span><span class="n">raw_data</span><span class="p">[</span><span class="s1">&#39;feature_names&#39;</span><span class="p">],</span>
    <span class="n">class_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">raw_data</span><span class="p">[</span><span class="s1">&#39;target_names&#39;</span><span class="p">])</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Step-3.-Interpreter-the-model-with-training-data">
<h3>Step 3. Interpreter the model with training data<a class="headerlink" href="#Step-3.-Interpreter-the-model-with-training-data" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="Model-Interpretation">
<h3>Model Interpretation<a class="headerlink" href="#Model-Interpretation" title="Permalink to this headline">¶</a></h3>
<p>The interpreter explains the model by aggregate explainations based on predicted classes. By calling <code class="docutils literal notranslate"><span class="pre">interpret_model()</span></code> with training data, the explainer will explain each sample on a local manner and aggregate the local explanations on each class to provide a global interpretation statistically. For now, we support 3 types of statistical aggregation: - top_k: how often a feature appears in the top K features in the explanation - average_score: average score for each feature in the
explanation - average_ranking: average ranking for each feature in the explanation</p>
<p>Default type is <code class="docutils literal notranslate"><span class="pre">top_k</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">stats</span> <span class="o">=</span> <span class="n">model_interpreter</span><span class="o">.</span><span class="n">interpret_model</span><span class="p">(</span><span class="n">samples</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">stats_type</span><span class="o">=</span><span class="s1">&#39;top_k&#39;</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
../../xai/model/interpreter/model_interpreter.py:83: UserWarning: Interpret 100/455 samples
  idx + 1, len(samples)))
../../xai/model/interpreter/model_interpreter.py:83: UserWarning: Interpret 200/455 samples
  idx + 1, len(samples)))
../../xai/model/interpreter/model_interpreter.py:83: UserWarning: Interpret 300/455 samples
  idx + 1, len(samples)))
../../xai/model/interpreter/model_interpreter.py:83: UserWarning: Interpret 400/455 samples
  idx + 1, len(samples)))
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">class_stats</span><span class="p">,</span> <span class="n">total_count</span> <span class="o">=</span> <span class="n">stats</span>
<span class="n">num_of_top_explanation</span> <span class="o">=</span> <span class="mi">15</span>
<span class="k">for</span> <span class="n">_class</span><span class="p">,</span><span class="n">_explanation_ranking</span> <span class="ow">in</span> <span class="n">class_stats</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Interpretation for Class </span><span class="si">%s</span><span class="s1">&#39;</span><span class="o">%</span><span class="k">_class</span>)
    <span class="n">plotter</span><span class="o">.</span><span class="n">plot_feature_importance_ranking</span><span class="p">([(</span><span class="n">key</span><span class="p">,</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span><span class="n">value</span> <span class="ow">in</span> <span class="n">_explanation_ranking</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
                                            <span class="p">[:</span><span class="n">num_of_top_explanation</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Interpretation for Class 1
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_29_1.png" src="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_29_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Interpretation for Class 0
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_29_3.png" src="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_29_3.png" />
</div>
</div>
</div>
<div class="section" id="Error-Analaysis">
<h3>Error Analaysis<a class="headerlink" href="#Error-Analaysis" title="Permalink to this headline">¶</a></h3>
<p>Error analysis helps to aggregate explanations on samples that are wrongly classified in the validation data set.</p>
<p>By calling function <code class="docutils literal notranslate"><span class="pre">error_analysis()</span></code>, it returns a stats of top explanations for wrongly classified samples.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">stats</span> <span class="o">=</span> <span class="n">model_interpreter</span><span class="o">.</span><span class="n">error_analysis</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">valid_x</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">valid_y</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">stats_type</span><span class="o">=</span><span class="s1">&#39;average_score&#39;</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
../../xai/model/interpreter/model_interpreter.py:128: UserWarning: Analyze 10/114 samples
  idx + 1, len(valid_x)))
../../xai/model/interpreter/model_interpreter.py:128: UserWarning: Analyze 20/114 samples
  idx + 1, len(valid_x)))
../../xai/model/interpreter/model_interpreter.py:128: UserWarning: Analyze 30/114 samples
  idx + 1, len(valid_x)))
../../xai/model/interpreter/model_interpreter.py:128: UserWarning: Analyze 40/114 samples
  idx + 1, len(valid_x)))
../../xai/model/interpreter/model_interpreter.py:128: UserWarning: Analyze 50/114 samples
  idx + 1, len(valid_x)))
../../xai/model/interpreter/model_interpreter.py:128: UserWarning: Analyze 60/114 samples
  idx + 1, len(valid_x)))
../../xai/model/interpreter/model_interpreter.py:128: UserWarning: Analyze 70/114 samples
  idx + 1, len(valid_x)))
../../xai/model/interpreter/model_interpreter.py:128: UserWarning: Analyze 80/114 samples
  idx + 1, len(valid_x)))
../../xai/model/interpreter/model_interpreter.py:128: UserWarning: Analyze 90/114 samples
  idx + 1, len(valid_x)))
../../xai/model/interpreter/model_interpreter.py:128: UserWarning: Analyze 100/114 samples
  idx + 1, len(valid_x)))
../../xai/model/interpreter/model_interpreter.py:128: UserWarning: Analyze 110/114 samples
  idx + 1, len(valid_x)))
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">num_of_top_explanation</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">for</span> <span class="p">(</span><span class="n">gt_class</span><span class="p">,</span><span class="n">predict_class</span><span class="p">),(</span><span class="n">_explanation_dict</span><span class="p">,</span><span class="n">num_sample</span><span class="p">)</span> <span class="ow">in</span> <span class="n">stats</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> sample from class [</span><span class="si">%s</span><span class="s1">] is wrongly classified as class[</span><span class="si">%s</span><span class="s1">]&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">num_sample</span><span class="p">,</span><span class="n">gt_class</span><span class="p">,</span><span class="n">predict_class</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; - Top reasons that they are predicted as class[</span><span class="si">%s</span><span class="s1">]&#39;</span><span class="o">%</span><span class="k">predict_class</span>)
    <span class="n">plotter</span><span class="o">.</span><span class="n">plot_feature_importance_ranking</span><span class="p">([(</span><span class="n">key</span><span class="p">,</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span><span class="n">value</span> <span class="ow">in</span> <span class="n">_explanation_dict</span><span class="p">[</span><span class="n">predict_class</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
                                            <span class="p">[:</span><span class="n">num_of_top_explanation</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
3 sample from class [1] is wrongly classified as class[0]
 - Top reasons that they are predicted as class[0]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_32_1.png" src="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_32_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
2 sample from class [0] is wrongly classified as class[1]
 - Top reasons that they are predicted as class[1]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_32_3.png" src="../../_images/tutorials_model_interpreter_tutorial_model_interpreter_32_3.png" />
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../model/model.html" class="btn btn-neutral float-right" title="model package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../../training_module_tutorial.html" class="btn btn-neutral float-left" title="XAI Model tutorials" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Wang Jin, Sean Saito, Chai Wei Tah, Ni Peng, Shu Zhen, Karthik Muthuswamy, Amrit Raj

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>