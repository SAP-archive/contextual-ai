{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML Report Generation\n",
    "\n",
    "## (*) Prerequisite\n",
    "\n",
    "### Install required packages\n",
    "1. Go to the root directory and install the required packages:\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "2. set your jupyter notebook kernel correctly to the environment with all required packages.\n",
    "\n",
    "\n",
    "### Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (A) Generate PDF Report\n",
    "\n",
    "This demo is to use XAI report formatter (a.k.a `xai.formatter.report`) to generate report content.\n",
    "### Step 1: Create Report object\n",
    "Create a report object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xai.formatter import Report\n",
    "report = Report(name='First Sample Report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the report name is use as page header:\n",
    "  \n",
    "![Report Header](formatter_html_images/sample-report-header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create section and add detail to report \n",
    "Content refer a detail block inside report. Contextual AI library group certain popular detail into business group, some examples includes but not limited to:\n",
    "- Dataset distribution\n",
    "- Feature value distribution (based on feature type: categorical, numeric, text, etc.)\n",
    "- Evaluation result summary\n",
    "- Feature importance\n",
    "- Learning curve history\n",
    "- ...\n",
    "\n",
    "There is pre-defined order of the report structure, it's like a `section` of the report: \n",
    "The pre-defined order is in following order:\n",
    "1. Cover Contents\n",
    "2. Content Table\n",
    "3. Detail Contents\n",
    "\n",
    "Each content can be added to `overview` (overview section) and `detail` (details section) using:\n",
    "- Add content to overview section with - `report.overview.add_xx`\n",
    "- Add content to details section with - `report.detail.add_xx`\n",
    "If there is no content added, the respecitve section will not be create.\n",
    "\n",
    "The content table section is optional but `enabled` by default, call `has_content_table` and set indicator as `False` to disable.  There is no pre-defined item in content table, it is depends on the implementation of inherited `writer`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1: Navigation design for HtmlWriter \n",
    "For instance, in _HtmlWriter_ implementation of `SectionTitle` is added to navigration table.\n",
    "- `add_section_title`: add as HTML Heading H1 Tags\n",
    "- `add_header_level_1`: add as HTML Heading H2 Tags with numbering (e.g. 1, 2, 3, ..)\n",
    "- `add_header_level_2`: add as HTML Heading H3 Tags with numbering  (e.g. 1.1, 1.2, 1.3, 2.1, ..) \n",
    "- `add_header_level_3`: add as HTML Heading H4 Tags with numbering  (e.g. 1.1.1, 1.1.2, 2.1.1, 2.1.2, ..) \n",
    "\n",
    "Upon generate, the content table will be in the follow format: \n",
    "\n",
    "![Content Table](formatter_html_images/first-sample-report_content-table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2: Create Cover Section\n",
    "Add content to overview section with - report.overview.add_xx\n",
    "- `add_section_title`: add section title with ribbon\n",
    "- `add_paragraph`: add section paragraph\n",
    "\n",
    "Below is a sample to create section with title `Summary` and add paragraph to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Cover Section\n",
    "report.overview.add_section_title(text=\"Summary\")\n",
    "report.overview.add_paragraph(text=\"This is summary Info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the overview section will be in the follow format:\n",
    "\n",
    "![Cover Contents](formatter_html_images/first-sample-report-overview-content.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: Create Content Section 1\n",
    "Add content to detail section with - report.detail.add_xx\n",
    "- `add_header_1`: add section hearder 1\n",
    "- `add_header_2`: add section hearder 2\n",
    "- `add_header_3`: add section hearder 3\n",
    "\n",
    "Below is a sample to create header `Section 1` and add paragraph to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Contents Section - Header\n",
    "report.detail.add_section_title(text=\"Example of Section Title 1\")\n",
    "#### Header Level 1 and it paragraph\n",
    "report.detail.add_header_level_1(text='Section 1 Header 1')\n",
    "report.detail.add_paragraph(text=\"This is content Info of header 1\")\n",
    "#### Header Level 2 and it paragraph\n",
    "report.detail.add_header_level_2(text='Section 1 Header 2')\n",
    "report.detail.add_paragraph(text=\"This is content Info of header 2\")\n",
    "#### Header Level 3 and it paragraph\n",
    "report.detail.add_header_level_3(text='Section 1 Header 3')\n",
    "report.detail.add_paragraph(text=\"This is content Info of header 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the detail section 1 will be in the follow format:\n",
    "\n",
    "![Content Section Header 1](formatter_html_images/first-sample-report-content-section-header-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4: Create Content Section 2\n",
    "Add content to detail section with - report.detail.add_xx\n",
    "- `add_paragraph_title`: add paragraph hearder \n",
    "\n",
    "Below is a sample to create header `Section 2` and add paragraph to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Contents Section - more\n",
    "report.detail.add_section_title(\"Example for Section Title 2\")\n",
    "#### Header Level 1 \n",
    "report.detail.add_header_level_1(text='Section 2 Header 1')\n",
    "### Add Level 2 and it paragraph\n",
    "report.detail.add_header_level_2(text='Section 2 Header 2')\n",
    "report.detail.add_paragraph(text=\"Some desc on header 2 in section 2 ...\")\n",
    "### Add another paragraph title\n",
    "report.detail.add_paragraph_title(text='Paragraph Title inside section 2 header 2')\n",
    "report.detail.add_paragraph(text=\"Another disc under paragraph title ...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the detail section 2 will be in the follow format:\n",
    "\n",
    "![Content Section Header 2](formatter_html_images/first-sample-report-content-section-header-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Generate the report\n",
    "\n",
    "Finally, call `generate` with `writer` object to compile the report.\n",
    "\n",
    "Below is sample to generate report in HTML format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report generated : /Users/i062308/Development/Explainable_AI/tutorials/formatter/hypertext_markup/sample_output/first-sample-report.html\n"
     ]
    }
   ],
   "source": [
    "from xai.formatter import HtmlWriter\n",
    "report.generate(writer=HtmlWriter(name='first-sample-report', path='./sample_output'))\n",
    "print(\"report generated : %s/sample_output/first-sample-report.html\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (B) Contents Examples\n",
    "The following section introduces a default design of report, which includes the following parts and each will be shown with a sample dummy data:\n",
    "- **0. Cover page** (display at the beginning of the report but generated at the end of whole process)\n",
    "- **1. Data Analysis**\n",
    "- **2. Feature Analysis**\n",
    "- **3. Training Analysis**\n",
    "    - *3.1 Hyperparameter Tuning*\n",
    "    - *3.2 Learning Curve (for deep learning)*\n",
    "- **4. Evaluation Analysis**\n",
    "- **5. Recommendataion Analysis (TBE)**\n",
    "\n",
    "First load sample data and create a report object :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of      PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  Birthday  \n",
      "0        0         A/5 21171   7.2500   NaN        S  19701007  \n",
      "1        0          PC 17599  71.2833   C85        C  19630213  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  19700419  \n",
      "3        0            113803  53.1000  C123        S  19670812  \n",
      "4        0            373450   8.0500   NaN        S  19770105  \n",
      "..     ...               ...      ...   ...      ...       ...  \n",
      "886      0            211536  13.0000   NaN        S  19650123  \n",
      "887      0            112053  30.0000   B42        S  19660706  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  19650509  \n",
      "889      0            111369  30.0000  C148        C  19620308  \n",
      "890      0            370376   7.7500   NaN        Q  19630117  \n",
      "\n",
      "[891 rows x 13 columns]>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append('../../../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "### Load Data\n",
    "training_file_name = './../sample_data/titanic.csv'\n",
    "data = pd.read_csv(training_file_name)\n",
    "### Add dummy birthday to demonstrate datetime presentation\n",
    "bday = []\n",
    "for i in range(len(data)):\n",
    "    year = np.random.randint(low=1960, high=1979)\n",
    "    month = np.random.randint(low=1, high=12)\n",
    "    day = np.random.randint(low=1, high=28)\n",
    "    bday.append(\"%s\" % (10000 * year + 100 * month + day))\n",
    "data['Birthday'] = bday\n",
    "\n",
    "label_column = 'Survived'\n",
    "print(data.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xai.formatter.report.base.Report object at 0x1226429b0>\n"
     ]
    }
   ],
   "source": [
    "from xai.data.constants import DATATYPE\n",
    "from xai.data import DataUtil\n",
    "from xai.model.interpreter import FeatureInterpreter\n",
    "from xai.formatter import Report\n",
    "\n",
    "report = Report(name='Simple Report')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the report name is use as page header:\n",
    "\n",
    "![Report Header](formatter_html_images/sample-report-header-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Analysis \n",
    "The section includes all the information for data analysis. By default, it should have the following information:\n",
    "- Class distribution (for classification problem)\n",
    "- Data field attribute\n",
    "- Data field value distribution\n",
    "- Missing value check\n",
    "\n",
    "Let's add paragraph to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Data Analysis Section\n",
    "report.detail.add_section_title(\"Example for Data Analysis \")\n",
    "### Add Header Level 1\n",
    "report.detail.add_header_level_1(text='Data Analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the detail data analysis section will be in the follow format:\n",
    "\n",
    "![Data Analysis](formatter_html_images/sample-report-data-analysis-section.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Class Distribution\n",
    "This section displays the distribution of each class given a label. It's for classification problem. The detail is created with `add_dataset_distribution`. \n",
    "\n",
    "A sample is shown as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add Header Level 2\n",
    "report.detail.add_header_level_2(text='Data Class Distribution')\n",
    "### Add Dataset distribution\n",
    "label_distributions = DataUtil.get_label_distribution(data=data, label=label_column)\n",
    "report.detail.add_data_set_distribution(label_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the data class distribution content will be in the follow format:\n",
    "\n",
    "![Data Class Distribution Info 1](formatter_html_images/sample-report-data-class-distribution-1.png)\n",
    "\n",
    "![Data Class Distribution Bar-Chart 1](formatter_html_images/sample-report-data-class-distribution-image-1.png)\n",
    "\n",
    "![Data Class Distribution Info 2](formatter_html_images/sample-report-data-class-distribution-2.png)\n",
    "\n",
    "![Data Class Distribution Bar-Chart 2](formatter_html_images/sample-report-data-class-distribution-image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Retrieve data type and statictis\n",
    "This section displays the attribute for all data fields. \n",
    "\n",
    "First get the data type and statistic as shown as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../../xai/data/helper.py:148: UserWarning: Warning: the feature [PassengerId] is suspected to be identifierable feature. \n",
      "[Examples]: [1, 2, 3, 4, 5]\n",
      "\n",
      "  '[Examples]: %s\\n' % (column, col_data.tolist()[:5]))\n",
      "../../../xai/data/helper.py:148: UserWarning: Warning: the feature [Ticket] is suspected to be identifierable feature. \n",
      "[Examples]: ['A/5 21171', 'PC 17599', 'STON/O2. 3101282', '113803', '373450']\n",
      "\n",
      "  '[Examples]: %s\\n' % (column, col_data.tolist()[:5]))\n",
      "../../../xai/data/helper.py:148: UserWarning: Warning: the feature [Cabin] is suspected to be identifierable feature. \n",
      "[Examples]: [nan, 'C85', nan, 'C123', nan]\n",
      "\n",
      "  '[Examples]: %s\\n' % (column, col_data.tolist()[:5]))\n",
      "../../../xai/data/helper.py:223: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[column][data[column].isnull()] = 'NAN'\n"
     ]
    }
   ],
   "source": [
    "### Get data types\n",
    "feature, valid_feature_names, valid_feature_types, meta = DataUtil.get_column_types(data=data, \n",
    "                                                                                    threshold=0.3, \n",
    "                                                                                    label=label_column)\n",
    "### Get Data Stats\n",
    "stats = DataUtil.get_data_statistics(data=data,\n",
    "                                     feature_names=valid_feature_names,\n",
    "                                     feature_types=valid_feature_types,\n",
    "                                     label=label_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Data Field Attribute\n",
    "This section displays the attribute for all data fields. The content is created with `add_data_attributes`. \n",
    "\n",
    "The data passed in should be a dict. For each item, the key is the field name, the value is a second-level dict with items of which key is the attribute name and value is the attribute value.\n",
    "\n",
    "A sample is shown as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add Header Level 2\n",
    "report.detail.add_header_level_2(text='Data Field Attribute')\n",
    "### Data Field Attribute\n",
    "report.detail.add_data_attributes(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the data field attribute detail will be in the follow format:\n",
    "\n",
    "![Data Field Attribute](formatter_html_images/sample-report-data-field-attribute.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Missing Value Check\n",
    "This section displays the missing value checking. The content is created with add_data_missing_value.\n",
    "\n",
    "The function takes in two inputs: one is `missing_count` which is a dict with items of which key is field name and value is the count or ratio of missing attribute. \n",
    "\n",
    "A sample is shown as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Add Header Level 2\n",
    "report.detail.add_header_level_2(text='Data Missing Value Check')\n",
    "### Missing value count\n",
    "missing_count, total_count = \\\n",
    "DataUtil.get_missing_value_count(data=data,\n",
    "                                 feature_names=valid_feature_names,\n",
    "                                 feature_types=valid_feature_types)\n",
    "report.detail.add_data_missing_value(missing_count=dict(missing_count),\n",
    "                                     total_count=total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the data missing value check detail will be in the follow format:\n",
    "\n",
    "![Data Missing Value](formatter_html_images/sample-report-data-missing-value.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Data Field Distribution\n",
    "\n",
    "This section displays value distribution for data fields. `xai.data_explorer` package analyzes the distribution for the following types:\n",
    "- Categorical\n",
    "- Numerical\n",
    "- Free Text\n",
    "- Datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add Header Level 2\n",
    "report.detail.add_header_level_2(text='Data Field Distribution')\n",
    "### Data Field Distribution Desc\n",
    "report.detail.add_paragraph(text='This section displays distribution for categorical fields, numerical fields and text fields.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the data field distribution header will be in the follow format: \n",
    "\n",
    "![Data Field Distribution](formatter_html_images/sample-report-data-field-distribution.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.1 Categorical Field Distribution\n",
    "For categorical field, the value frequency under each label will be shown. \n",
    "See details about `xai.data_explorer.categorical_analyzer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add Header Level 3\n",
    "report.detail.add_header_level_3(text='Categorical Field Distribution')\n",
    "### Categorical field distribution\n",
    "for field_name in feature[DATATYPE.CATEGORY]:\n",
    "    labelled_stats, all_stats = stats[field_name]\n",
    "    report.detail.add_categorical_field_distribution(field_name=field_name, field_distribution=labelled_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the catagorical field distribution detail will be in the follow format:\n",
    "\n",
    "![Categorical Field Distribution](formatter_html_images/sample-report-data-field-categorical-distribution.png)\n",
    "\n",
    "![Categorical Field Distribution Title 1](formatter_html_images/sample-report-data-field-categorical-distribution-title-1.png)\n",
    "![Categorical Field Distribution Image 1](formatter_html_images/sample-report-data-field-categorical-distribution-image-1.png)\n",
    "\n",
    "![Categorical Field Distribution Title 2](formatter_html_images/sample-report-data-field-categorical-distribution-title-2.png)\n",
    "![Categorical Field Distribution Image 2](formatter_html_images/sample-report-data-field-categorical-distribution-image-2.png)\n",
    "\n",
    "![Categorical Field Distribution Title 3](formatter_html_images/sample-report-data-field-categorical-distribution-title-3.png)\n",
    "![Categorical Field Distribution Image 3](formatter_html_images/sample-report-data-field-categorical-distribution-image-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.2 Numerical Field Distribution\n",
    "For numerical fields, the value distribution will shown as histogram and KDE curve. Main statistics (e.g. max, min, mean, median) will also be shown.\n",
    "See details about `xai.data_explorer.numerical_analyzer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add Header Level 3\n",
    "report.detail.add_header_level_3(text='Numerical Field Distribution')\n",
    "### Numerical field distribution\n",
    "for field_name in feature[DATATYPE.NUMBER]:\n",
    "    labelled_stats, all_stats = stats[field_name]\n",
    "    report.detail.add_numeric_field_distribution(field_name=field_name, field_distribution=labelled_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the numerical field distribution detail will be in the follow format:\n",
    "\n",
    "![Numerical Field Distribution 1](formatter_html_images/sample-report-data-field-numerical-distribution-1.png)\n",
    "![Numerical Field Distribution Chart 1](formatter_html_images/sample-report-data-field-numerical-distribution-image-1.png)\n",
    "\n",
    "![Numerical Field Distribution 2](formatter_html_images/sample-report-data-field-numerical-distribution-2.png)\n",
    "![Numerical Field Distribution Chart 2](formatter_html_images/sample-report-data-field-numerical-distribution-image-2.png)\n",
    "\n",
    "![Numerical Field Distribution 3](formatter_html_images/sample-report-data-field-numerical-distribution-3.png)\n",
    "![Numerical Field Distribution Chart 3](formatter_html_images/sample-report-data-field-numerical-distribution-image-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.3 Text Field Distribution\n",
    "For text fields, a woldcloud will be shown with a size weigthed on the TF-IDF. Besides, Contextual AI has some pre-defined text patterns, such as `Email`, `URL`, `Datetime`. If the text field is analyzed with Contextual AI Data Explorer package, the percentage of documents contains each pattern will also be analyzed and displayed.\n",
    "See details about `xai.data_explorer.text_analyzer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add Header Level 3\n",
    "report.detail.add_header_level_3(text='Text Field Distribution')\n",
    "### Text field distribution\n",
    "for field_name in feature[DATATYPE.FREETEXT]:\n",
    "    labelled_stats, all_stats = stats[field_name]\n",
    "    report.detail.add_text_field_distribution(field_name=field_name, field_distribution=labelled_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the text field distribution detail will be in the follow format:\n",
    "\n",
    "![Text Field Distribution 1](formatter_html_images/sample-report-data-field-text-distribution-1.png)\n",
    "![Text Field Distribution Word Cloud 1](formatter_html_images/sample-report-data-field-text-distribution-wc-1.png)\n",
    "\n",
    "![Text Field Distribution 2](formatter_html_images/sample-report-data-field-text-distribution-2.png)\n",
    "![Text Field Distribution Word Cloud 2](formatter_html_images/sample-report-data-field-text-distribution-wc-2.png)\n",
    "\n",
    "![Text Field Distribution 3](formatter_html_images/sample-report-data-field-text-distribution-3.png)\n",
    "![Text Field Distribution Word Cloud 3](formatter_html_images/sample-report-data-field-text-distribution-wc-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.4 DateTime Field Distribution\n",
    "For datetime fields, count on months/years will be show in an barchart. \n",
    "See details about `xai.data_explorer.datetime_analyzer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add Header Level 3\n",
    "report.detail.add_header_level_3(text='Datetime Field Distribution')\n",
    "### Datetime field distribution\n",
    "for field_name in feature[DATATYPE.DATETIME]:\n",
    "    labelled_stats, all_stats = stats[field_name]\n",
    "    report.detail.add_datetime_field_distribution(field_name=field_name, field_distribution=labelled_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the date time field distribution detail will be in the follow format:\n",
    "\n",
    "![DateTime Field Distribution](formatter_html_images/sample-report-data-field-datetime-distribution.png)\n",
    "\n",
    "![DateTime Field Distribution](formatter_html_images/sample-report-data-field-datetime-distribution-chart.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5: Generate the report\n",
    "\n",
    "At any moment, call `generate` with `writer` object to compile the report. Since, no content is added to overview section - no overview section been generated.\n",
    "\n",
    "Below is sample to generate report in PDF format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report generated : /Users/i062308/Development/Explainable_AI/tutorials/formatter/hypertext_markup/sample_output/sample-report-with-data-section-only.html\n"
     ]
    }
   ],
   "source": [
    "from xai.formatter import HtmlWriter\n",
    "report.generate(writer=HtmlWriter(name='sample-report-with-data-section-only', path='./sample_output'))\n",
    "print(\"report generated : %s/sample_output/sample-report-with-data-section-only.html\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Analysis\n",
    "This section shows analysis for feature importance. It shows as a barchart and feature importance above a thresdhold as a table. A sample is shown as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Feature Analysis Section as new page\n",
    "report.detail.add_new_page()\n",
    "report.detail.add_section_title(\"Example for Feature Analysis \")\n",
    "### Add Header Level 1\n",
    "report.detail.add_header_level_1(text='Feature Analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the content feature analysis section will be in the follow format:\n",
    "\n",
    "![Feature Analysis](formatter_html_images/sample-report-feature-analysis-section.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Add Header Level 2\n",
    "report.detail.add_header_level_2(text='Feature Importance')\n",
    "### Feature Importance\n",
    "path =  Path('./../sample_data/model.pkl')\n",
    "model = pd.read_pickle(str(path))\n",
    "path = Path('./../sample_data/train_data.csv')\n",
    "data = pd.read_csv(str(path))\n",
    "# -- csv including header --\n",
    "feature_names = data.columns\n",
    "\n",
    "fi = FeatureInterpreter(feature_names=feature_names)\n",
    "rank = fi.get_feature_importance_ranking(trained_model=model, train_x=data, method='default')\n",
    "\n",
    "report.detail.add_feature_importance(importance_ranking=rank, importance_threshold=0.005)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the feature importance detail will be in the follow format:\n",
    "\n",
    "![Feature Importance Desc](formatter_html_images/sample-report-feature-importance-0.png)\n",
    "\n",
    "![Feature Importance Figure](formatter_html_images/sample-report-feature-importance-1.png)\n",
    "\n",
    "![Feature Importance Table](formatter_html_images/sample-report-feature-importance-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2: Generate the report\n",
    "\n",
    "At any moment, you may call `generate` with `writer` object to compile the report. Since, no content is added to overview section - no overview section been generated.\n",
    "\n",
    "Below is sample to generate report in PDF format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report generated : /Users/i062308/Development/Explainable_AI/tutorials/formatter/hypertext_markup/sample_output/sample-report-with-data-and-feature-section.html\n"
     ]
    }
   ],
   "source": [
    "from xai.formatter import HtmlWriter\n",
    "report.generate(writer=HtmlWriter(name='sample-report-with-data-and-feature-section', path='./sample_output'))\n",
    "print(\"report generated : %s/sample_output/sample-report-with-data-and-feature-section.html\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training Analysis\n",
    "This section shows training analysis, and presents information while training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Training Analysis Section as new page\n",
    "report.detail.add_new_page()\n",
    "report.detail.add_section_title(\"Example for Training Analysis \")\n",
    "### Add Header Level 1\n",
    "report.detail.add_header_level_1(text='Training Analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the detail Training analysis section will be in the follow format:\n",
    "\n",
    "![Training Analysis](formatter_html_images/sample-report-training-analysis-section.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Hyperparameter Tuning\n",
    "The section shows model metric monitoring while tuning hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_space: {'NumTrees': '(20, 500)', 'RandomState': '(200, 1000)', 'MaxFeature': 'auto', 'MinSplit': 2, 'MaxDepth': ['None', 4, 5, 6]}\n",
      "best_idx: 3\n",
      "history [first 2 samples]: {'0': {'params': {'MaxDepth': 6, 'MaxFeature': 'auto', 'MinSampleSplit': 2, 'NumTrees': 448.0, 'RandomState': 685.0}, 'val_scores': {'accuracy': 0.075, 'f1': 0.07493575942773803, 'precision': 0.4217391304347826, 'recall': 0.4342105263157895, 'auc': 0.4009502923976608}}, '1': {'params': {'MaxDepth': 6, 'MaxFeature': 'auto', 'MinSampleSplit': 2, 'NumTrees': 351.0, 'RandomState': 351.0}, 'val_scores': {'accuracy': 0.0875, 'f1': 0.08748415771107138, 'precision': 0.44510335479498475, 'recall': 0.44078947368421056, 'auc': 0.40570175438596495}}}\n",
      "benchmark_metric: accuracy\n",
      "benchmark_threshold: 0.8\n",
      "non_hyperopt_score: 0.8166666666666667\n"
     ]
    }
   ],
   "source": [
    "### Add Header Level 2\n",
    "report.detail.add_header_level_2(text='Hyperparameter Tuning')\n",
    "### Hyperparameter Tuning\n",
    "with open('./../sample_data/hyperparameter_tuning.json', 'r') as f:\n",
    "    hyperparameter_tuning = json.load(f)\n",
    "\n",
    "print('search_space:',hyperparameter_tuning['search_space'])\n",
    "print('best_idx:',hyperparameter_tuning['best_idx'])\n",
    "print('history [first 2 samples]:',\n",
    "      {k:hyperparameter_tuning['history'][k] for k in list(hyperparameter_tuning['history'].keys())[:2]})\n",
    "print('benchmark_metric:',hyperparameter_tuning['benchmark_metric'])\n",
    "print('benchmark_threshold:',hyperparameter_tuning['benchmark_threshold'])\n",
    "print('non_hyperopt_score:',hyperparameter_tuning['non_hyperopt_score'])\n",
    "\n",
    "report.detail.add_hyperparameter_tuning(history=hyperparameter_tuning['history'],\n",
    "                                         best_idx=hyperparameter_tuning['best_idx'],\n",
    "                                         search_space=hyperparameter_tuning['search_space'],\n",
    "                                         benchmark_metric=hyperparameter_tuning['benchmark_metric'],\n",
    "                                         benchmark_threshold=hyperparameter_tuning['benchmark_threshold'],\n",
    "                                         non_hyperopt_score=hyperparameter_tuning['non_hyperopt_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the hyperparameter tuning detail will be in the follow format:\n",
    "\n",
    "![Hyperparameter Tuning Desc](formatter_html_images/sample-report-hyperparameter-tuning-1.png)\n",
    "\n",
    "![Hyperparameter Tuning Result](formatter_html_images/sample-report-hyperparameter-tuning-2.png)\n",
    "\n",
    "![Hyperparameter Tuning Result Summary](formatter_html_images/sample-report-hyperparameter-tuning-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Learning Curve (for deep learning)\n",
    "The section shows model metric monitoring while training (a.k.a learning curve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_idx: 0\n",
      "history [first 2 samples]: {'0': {'val_scores': {'loss': 0.769659698009491, 'accuracy': 0.9515625238418579, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.5082619190216064}}, '1': {'val_scores': {'loss': 0.7648007273674011, 'accuracy': 0.948437511920929, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.4868066608905792}}}\n",
      "benchmark_metric: accuracy\n",
      "benchmark_threshold: 0.9\n",
      "training_params: {'Sequence time step': 15, 'Sequence feature length': 125, 'Attribute feature length': 294, 'RNN layer number': 2, 'RNN keep probability': 0.8, 'DNN layer number': 1, 'DNN regularizer': 'L2 (scale: 0.06)'}\n"
     ]
    }
   ],
   "source": [
    "### Add Header Level 2\n",
    "report.detail.add_header_level_2(text='Deep Learning Training')\n",
    "### Learning Curve\n",
    "with open('./../sample_data/learning_curve.json', 'r') as f:\n",
    "    learning_curve = json.load(f)\n",
    "\n",
    "print('best_idx:',learning_curve['best_idx'])\n",
    "print('history [first 2 samples]:',\n",
    "      {k:learning_curve['history'][k] for k in list(learning_curve['history'].keys())[:2]})\n",
    "print('benchmark_metric:',learning_curve['benchmark_metric'])\n",
    "print('benchmark_threshold:',learning_curve['benchmark_threshold'])\n",
    "print('training_params:',learning_curve['training_params'])\n",
    "\n",
    "report.detail.add_learning_curve(history=learning_curve['history'],\n",
    "                                  best_idx=learning_curve['best_idx'],\n",
    "                                  benchmark_metric=learning_curve['benchmark_metric'],\n",
    "                                  benchmark_threshold=learning_curve['benchmark_threshold'],\n",
    "                                  training_params=learning_curve['training_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the learning curve detail will be in the follow format:\n",
    "\n",
    "![Learning Curve](formatter_html_images/sample-report-learning-curve-1.png)\n",
    "\n",
    "![Learning Curve Result](formatter_html_images/sample-report-learning-curve-2.png)\n",
    "\n",
    "![Learning Curve Result Summary](formatter_html_images/sample-report-learning-curve-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3: Generate the report\n",
    "\n",
    "At any moment, you may call `generate` with `writer` object to compile the report. Since, no content is added to overview section - no overview section been generated.\n",
    "\n",
    "Below is sample to generate report in PDF format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report generated : /Users/i062308/Development/Explainable_AI/tutorials/formatter/hypertext_markup/sample_output/sample-report-with-data-feature-training-section.html\n"
     ]
    }
   ],
   "source": [
    "from xai.formatter import HtmlWriter\n",
    "report.generate(writer=HtmlWriter(name='sample-report-with-data-feature-training-section', path='./sample_output'))\n",
    "print(\"report generated : %s/sample_output/sample-report-with-data-feature-training-section.html\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluation Analysis\n",
    "The section provides analysis on evaluation results. It is divided into 2 types: binary classification and multi-class classification. For each case, the following contents are displayed:\n",
    " - numeric metrics\n",
    " - confusion matrix\n",
    " - confidence distribution\n",
    " - reliability diagram (binary classification only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Evaluation Analysis Section as new page\n",
    "report.detail.add_new_page()\n",
    "report.detail.add_section_title(\"Example for Evaluation Analysis \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Binary Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add Header Level 1\n",
    "report.detail.add_header_level_1(text='Binary Classification Evaluation Analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the binary classification header will be in the follow format:\n",
    "\n",
    "![Binary Classification Evaluation](formatter_html_images/sample-report-binary-classification-evaluation.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1 Numeric Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('train', {'accuracy': 0.9627912640571594, 'precision': 0.02666666731238365, 'recall': 0.008547008968889713, 'f1': 0.012944985181093216, 'auc': 0.4609035849571228, 'CM': [[7890, 73], [232, 2]]}), ('validation', {'accuracy': 0.9576036930084229, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.4362090826034546, 'CM': [[1039, 14], [32, 0]]}), ('test', {'accuracy': 0.962892472743988, 'precision': 0.10000000149011612, 'recall': 0.032258063554763794, 'f1': 0.04878048971295357, 'auc': 0.4682953953742981, 'CM': [[1011, 9], [30, 1]]})]\n"
     ]
    }
   ],
   "source": [
    "### Add Header Level 2\n",
    "report.detail.add_header_level_2(text='Overall Result')\n",
    "### Numeric Metric\n",
    "with open('./../sample_data/binary_evaluation_results.json', 'r') as f:\n",
    "    eval_result = json.load(f)\n",
    "\n",
    "splits = eval_result.keys()\n",
    "numeric_metrics_list = []\n",
    "\n",
    "for split in splits:\n",
    "    label_eval_result = eval_result[split]\n",
    "    del(label_eval_result['vis_result'])\n",
    "    numeric_metrics_list.append((split, label_eval_result))\n",
    "print(numeric_metrics_list)\n",
    "\n",
    "report.detail.add_binary_class_evaluation_metric_results(numeric_metrics_list, \n",
    "                                                          notes='The section shows general results like accuracy, precision, recall.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the numeric metric detail will be in the follow format:\n",
    "\n",
    "![Numeric Metric](formatter_html_images/sample-report-numeric-metric.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('train', {'labels': ['Negative', 'Positive'], 'values': [[7890, 73], [232, 2]]}), ('validation', {'labels': ['Negative', 'Positive'], 'values': [[1039, 14], [32, 0]]}), ('test', {'labels': ['Negative', 'Positive'], 'values': [[1011, 9], [30, 1]]})]\n"
     ]
    }
   ],
   "source": [
    "### Add Header Level 2\n",
    "report.detail.add_header_level_2(text='Confusion Matrix')\n",
    "### Confusion Matrix\n",
    "with open('./../sample_data/binary_evaluation_results.json', 'r') as f:\n",
    "    eval_result = json.load(f)\n",
    "splits = eval_result.keys()\n",
    "confusion_matrix_list = []\n",
    "\n",
    "for split in splits:\n",
    "    label_eval_result = eval_result[split]\n",
    "    confusion_matrix_list.append((split, {\"labels\": [\"Negative\", \"Positive\"], \"values\": label_eval_result[\"CM\"]}))\n",
    "print(confusion_matrix_list)\n",
    "\n",
    "report.detail.add_confusion_matrix_results(confusion_matrix_tuple=confusion_matrix_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the confusion matrix detail will be in the follow format:\n",
    "  \n",
    "![Confusion Matrix](formatter_html_images/sample-report-confusion-matrix.png)\n",
    "\n",
    "![Confusion Matrix](formatter_html_images/sample-report-confusion-matrix-1.png)\n",
    "![Confusion Matrix](formatter_html_images/sample-report-confusion-matrix-2.png)\n",
    "![Confusion Matrix](formatter_html_images/sample-report-confusion-matrix-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.3 Confidence Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split name: train\n",
      " - probability: <class 'list'> [[0.3770688772201538, 0.6229311227798462], [0.41023093461990356, 0.5897691249847412], [0.4822709560394287, 0.5177291035652161]]\n",
      " - gt: <class 'list'> [0, 0, 0]\n",
      "Split name: validation\n",
      " - probability: <class 'list'> [[0.44429945945739746, 0.5557004809379578], [0.5415756702423096, 0.45842432975769043], [0.46190792322158813, 0.5380920171737671]]\n",
      " - gt: <class 'list'> [0, 0, 0]\n",
      "Split name: test\n",
      " - probability: <class 'list'> [[0.4792706072330475, 0.5207294225692749], [0.541035532951355, 0.4589644968509674], [0.47570356726646423, 0.5242964029312134]]\n",
      " - gt: <class 'list'> [0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "### Add Header Level 2\n",
    "report.detail.add_header_level_2(text='Confidence Distribution')\n",
    "### Confidence Distribution\n",
    "with open('./../sample_data/binary_evaluation_results.json', 'r') as f:\n",
    "    eval_result = json.load(f)\n",
    "\n",
    "splits = eval_result.keys()\n",
    "probability_plot_list = []\n",
    "\n",
    "for split in splits:\n",
    "    vis_result = eval_result[split]['vis_result']\n",
    "    probability_plot_list.append((split, vis_result))\n",
    "    print('Split name:',split)\n",
    "    for key, value in vis_result.items():\n",
    "        print(' - %s:'%key, type(value), value[:3])\n",
    "    \n",
    "report.detail.add_binary_class_confidence_distribution(probability_plot_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the confidence distribution will be in the follow format:\n",
    "    \n",
    "![Confidence Distribution](formatter_html_images/sample-report-confidence-distribution.png)\n",
    "\n",
    "![Confidence Distribution](formatter_html_images/sample-report-confidence-distribution-1.png)\n",
    "![Confidence Distribution](formatter_html_images/sample-report-confidence-distribution-2.png)\n",
    "![Confidence Distribution](formatter_html_images/sample-report-confidence-distribution-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.4 Reliability Digram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split name: train\n",
      " - probability: <class 'list'> [[0.4792706072330475, 0.5207294225692749], [0.541035532951355, 0.4589644968509674], [0.47570356726646423, 0.5242964029312134]]\n",
      " - gt: <class 'list'> [0, 0, 0]\n",
      "Split name: validation\n",
      " - probability: <class 'list'> [[0.4792706072330475, 0.5207294225692749], [0.541035532951355, 0.4589644968509674], [0.47570356726646423, 0.5242964029312134]]\n",
      " - gt: <class 'list'> [0, 0, 0]\n",
      "Split name: test\n",
      " - probability: <class 'list'> [[0.4792706072330475, 0.5207294225692749], [0.541035532951355, 0.4589644968509674], [0.47570356726646423, 0.5242964029312134]]\n",
      " - gt: <class 'list'> [0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "### Add Header Level 2\n",
    "report.detail.add_header_level_2(text='Reliability Diagram')\n",
    "### Reliability Diagram\n",
    "with open('./../sample_data/binary_evaluation_results.json', 'r') as f:\n",
    "    eval_result = json.load(f)\n",
    "\n",
    "splits = eval_result.keys()\n",
    "probability_plot_list = []\n",
    "\n",
    "for split in splits:\n",
    "    label_eval_result = eval_result[split]['vis_result']\n",
    "    probability_plot_list.append((split, vis_result))\n",
    "    print('Split name:',split)\n",
    "    for key, value in vis_result.items():\n",
    "        print(' - %s:'%key, type(value), value[:3])\n",
    "\n",
    "report.detail.add_binary_class_reliability_diagram(probability_plot_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the reliability diagram will be in the follow format:\n",
    "  \n",
    "![Reliability Diagram](formatter_html_images/sample-report-reliability-diagram.png)\n",
    "\n",
    "![Reliability Diagram](formatter_html_images/sample-report-reliability-diagram-1.png)\n",
    "![Reliability Diagram](formatter_html_images/sample-report-reliability-diagram-2.png)\n",
    "![Reliability Diagram](formatter_html_images/sample-report-reliability-diagram-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Multi-class Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add Header Level 1\n",
    "report.detail.add_header_level_1(text='Multi-class Classification Evaluation Analysis')\n",
    "\n",
    "with open('./../sample_data/multi_evaluation_results.json', 'r') as f:\n",
    "    eval_result = json.load(f)\n",
    "\n",
    "label_key = 'label_1'\n",
    "label_eval_result = eval_result[label_key]\n",
    "vis_result = label_eval_result['vis_result']\n",
    "del (label_eval_result['vis_result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the multi-class classification header will be in the follow format:\n",
    "  \n",
    "![Multi-Class Classification Evaluation](formatter_html_images/sample-report-multi-class-classification-evaluation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1 Numeric Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_score': {'class': {'OTHER': 0.8106060606060606, 'PROFANITY': 0.0, 'ABUSE': 0.43083003952569177, 'INSULT': 0.03529411764705882}, 'average': 0.6306263638637892}, 'recall': {'class': {'OTHER': 0.9214208826695371, 'PROFANITY': 0.0, 'ABUSE': 0.3707482993197279, 'INSULT': 0.018633540372670808}, 'average': 0.6894586894586895}, 'precision': {'class': {'OTHER': 0.7235841081994928, 'PROFANITY': 0.0, 'ABUSE': 0.5141509433962265, 'INSULT': 0.3333333333333333}, 'average': 0.6246700003863861}, 'CM': {'labels': ['OTHER', 'PROFANITY', 'ABUSE', 'INSULT'], 'values': [[856, 0, 67, 6], [16, 0, 4, 0], [185, 0, 109, 0], [126, 0, 32, 3]]}}\n"
     ]
    }
   ],
   "source": [
    "### Add Header Level 2\n",
    "report.detail.add_header_level_2(text='Overall Result')\n",
    "### Numeric Metrics\n",
    "print(label_eval_result)\n",
    "\n",
    "report.detail.add_multi_class_evaluation_metric_results(('', label_eval_result),\n",
    "                                                        notes='The section shows general results like accuracy, precision, recall.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the multi-class numeric metric will be in the follow format:\n",
    "  \n",
    "![Multi Class Metric Result](formatter_html_images/sample-report-multi-class-numeric-metric.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': ['OTHER', 'PROFANITY', 'ABUSE', 'INSULT'], 'values': [[856, 0, 67, 6], [16, 0, 4, 0], [185, 0, 109, 0], [126, 0, 32, 3]]}\n"
     ]
    }
   ],
   "source": [
    "### Add Header Level 2\n",
    "report.detail.add_header_level_2(text='Confusion Matrix')\n",
    "### Confusion Matrix\n",
    "print(label_eval_result['CM'])\n",
    "\n",
    "\n",
    "report.detail.add_confusion_matrix_results(confusion_matrix_tuple=[('', label_eval_result['CM'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the multi-class confusion matrix will be in the follow format:\n",
    "  \n",
    "![Multi Class Confusion Matrix Result](formatter_html_images/sample-report-multi-class-confusion-matrix.png)\n",
    "![Multi Class Confusion Matrix Result](formatter_html_images/sample-report-multi-class-confusion-matrix-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.3 Confidence Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: OTHER\n",
      " - gt: <class 'list'> ['OTHER', 'OTHER', 'INSULT', 'OTHER']\n",
      " - probability: <class 'list'> [0.8916968852945533, 0.6004393436260155, 0.6709159285290026, 0.8776989624158892]\n",
      "Class: PROFANITY\n",
      " - gt: <class 'list'> []\n",
      " - probability: <class 'list'> []\n",
      "Class: ABUSE\n",
      " - gt: <class 'list'> ['ABUSE', 'INSULT', 'OTHER', 'INSULT']\n",
      " - probability: <class 'list'> [0.3997915305239952, 0.4321055255119627, 0.4272960507553194, 0.9063218066182464]\n",
      "Class: INSULT\n",
      " - gt: <class 'list'> ['INSULT', 'OTHER', 'OTHER', 'OTHER']\n",
      " - probability: <class 'list'> [0.4748126330295362, 0.4603932866512729, 0.4276429140622332, 0.3630582608615315]\n"
     ]
    }
   ],
   "source": [
    "### Add Header Level 2\n",
    "report.detail.add_header_level_2(text='Confidence Distribution')\n",
    "###  Probability Plot\n",
    "for class_name, class_value in vis_result.items():\n",
    "    print('Class:',class_name)\n",
    "    for key, value in class_value.items():\n",
    "        print(' - %s:'%key, type(value), value[:4])\n",
    "        \n",
    "report.detail.add_multi_class_confidence_distribution([('', vis_result)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the multi-class confidence distribution will be in the follow format:\n",
    "  \n",
    "![Multi Class Confidence Distribution Result](formatter_html_images/sample-report-multi-class-confidence-distribution.png)\n",
    "\n",
    "![Multi Class Confidence Distribution Result](formatter_html_images/sample-report-multi-class-confidence-distribution-1.png)\n",
    "![Multi Class Confidence Distribution Result](formatter_html_images/sample-report-multi-class-confidence-distribution-2.png)\n",
    "![Multi Class Confidence Distribution Result](formatter_html_images/sample-report-multi-class-confidence-distribution-3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3: Generate the report\n",
    "\n",
    "At any moment, you may call `generate` with `writer` object to compile the report. Since, no content is added to overview section - no overview section been generated.\n",
    "\n",
    "Below is sample to generate report in PDF format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../../xai/graphs/graph_generator.py:39: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ave_acc = np.sum(accuracy[condition]) / sample_num\n",
      "/Users/i062308/anaconda3/envs/xai-py37/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/i062308/anaconda3/envs/xai-py37/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report generated : /Users/i062308/Development/Explainable_AI/tutorials/formatter/hypertext_markup/sample_output/sample-report-with-data-feature-training-evaluation-section.html\n"
     ]
    }
   ],
   "source": [
    "from xai.formatter import HtmlWriter\n",
    "report.generate(writer=HtmlWriter(name='sample-report-with-data-feature-training-evaluation-section', path='./sample_output'))\n",
    "print(\"report generated : %s/sample_output/sample-report-with-data-feature-training-evaluation-section.html\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Recommendataion Analysis (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a set of content that special design to display summary info, such as:\n",
    "- Summary Notes\n",
    "- Model Information\n",
    "- Timing\n",
    "- Data Summary\n",
    "- Evaluation Result\n",
    "\n",
    "Please `take note` that:\n",
    "* It `DOES NOT` need to be called at the end of pipeline\n",
    "* It can be added in both `overview` and `content` section\n",
    "\n",
    "Below is sample to demostrate - add summary info to overview section:\n",
    "\n",
    "\n",
    "#### 5.1: Summary Notes\n",
    "Add overview section and simple summary as paragraph into overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.overview.add_section_title(text=\"Overview\")\n",
    "summary_notes_text = '''This report serves as a demo for the Contextual AI library. \n",
    "The data used to generate this report is not from any specific use case.\n",
    "Sorry for any inconsistency in the report data. \n",
    "'''\n",
    "report.overview.add_paragraph(summary_notes_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the summary paragraph (example as first content) will be in the follow format:\n",
    "\n",
    "![Summary Paragraph](formatter_html_images/sample-report-summary-paragraph.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2: Model Information\n",
    "The content is created by `add_model_info_summary`. It is designed to display the basid model information, such as `model_id`, `model_version` or any information specific to this training. \n",
    "\n",
    "The data should be passed in as a list of tuple, each tuple will be a key-value pair. If no data is provided to the content, `usecase_name`, `version`, `usecase_team` will be displayed as a default information. A sample is shown as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = [('Model ID','12345678'),\n",
    "              ('Model Version','v6'),\n",
    "              ('Scenario ID','111222333444555'),\n",
    "              ('Notes','This model is created as a beta version.')\n",
    "             ]\n",
    "report.overview.add_model_info_summary(model_info=model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the Model Info summary will be in the follow format:\n",
    "\n",
    "![Model Info Summary](formatter_html_images/sample-report-model-info-summary.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3: Timing\n",
    "The content is created by `add_training_timing`. It is designed to display the time spend at each stage of the training process, such as `data processing`, `feature extraction`, `training model` and `evaluation`. \n",
    "\n",
    "The data should be passed in as a list of tuple, each tuple will be a pair of stage name and time spend in seconds. A sample is shown as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing = [('Data Preprocessing', 1000),\n",
    "          ('Feature Engineering', 10000),\n",
    "          ('Training', 200200),\n",
    "          ('Evaluation', 30303)]\n",
    "report.overview.add_training_timing(timing=timing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the Training Timing summary will be in the follow format:\n",
    "\n",
    "![Training Time Summary](formatter_html_images/sample-report-training-time-summary.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4: Data Summary\n",
    "The content is created by `add_data_set_summary`. It is designed to display the quantity of samples used in each stage of training (a.k.a training, validation, testing). It can also be used to display the distribution among different classes.\n",
    "\n",
    "The data should be passed in as a list of tuple, each tuple will be a pair of dataset name and quantity. A sample is shown as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary = [('training', 10000), \n",
    "                ('validation', 2000), \n",
    "                ('testing', 1000)]\n",
    "report.overview.add_data_set_summary(data_summary=data_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the Dataset summary will be in the follow format:\n",
    "\n",
    "![Dataset Summary](formatter_html_images/sample-report-data-set-summary.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5: Evaluation Result Summary\n",
    "The content is created by `add_evaluation_result_summary`. It is designed to display the summary on evaluation result in a high-level. Only numeric metrics will be displayed, anything involves a list won't be shown in summary. For example, for multi-class classification, only the average metrics will be shown, also metric such like ROC and confusion matrix won't be shown here.\n",
    "\n",
    "The data should be passed in as a list of dict, each dict includes evaluation on one objective. For example, in a multi-label classication or multi-task machine learning problem, each dict will only regards on one label or one task. The function takes in as many as dict and display each of them in sequence.\n",
    "\n",
    "For each dict, each key-value pair should about a metric or an attribute. \n",
    " - If the value is a number or a str, the key-value pair will be displayed\n",
    " - If the value is a list, it will be ignored in display. \n",
    " - If the value is dict, the function will search the keyword `average` to display the average metric; otherwise, search the keyword `class` and calculate a macro average if it's a list of float. For other cases, the function will ignore this item.\n",
    " \n",
    "A sample is shown as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'field': 'Category I', 'labels': 'OTHER, OFFENSE', 'f1_score': {'class': {'OTHER': 0.7871690427698573, 'OFFENSE': 0.504739336492891}, 'average': 0.6916176820280062}, 'recall': {'class': {'OTHER': 0.8320775026910656, 'OFFENSE': 0.44842105263157894}, 'average': 0.7022792022792023}, 'precision': {'class': {'OTHER': 0.7468599033816425, 'OFFENSE': 0.5772357723577236}, 'average': 0.6894728220167127}}, {'field': 'Category II', 'labels': 'OTHER, PROFANITY, ABUSE, INSULT', 'f1_score': {'class': {'OTHER': 0.8106060606060606, 'PROFANITY': 0.0, 'ABUSE': 0.43083003952569177, 'INSULT': 0.03529411764705882}, 'average': 0.6306263638637892}, 'recall': {'class': {'OTHER': 0.9214208826695371, 'PROFANITY': 0.0, 'ABUSE': 0.3707482993197279, 'INSULT': 0.018633540372670808}, 'average': 0.6894586894586895}, 'precision': {'class': {'OTHER': 0.7235841081994928, 'PROFANITY': 0.0, 'ABUSE': 0.5141509433962265, 'INSULT': 0.3333333333333333}, 'average': 0.6246700003863861}}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('./../sample_data/evaluation_result_summary.json','r') as f:\n",
    "    evaluation_result_data = json.load(f)\n",
    "print(evaluation_result_data)\n",
    "\n",
    "report.overview.add_evaluation_result_summary(evaluation_result=evaluation_result_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generated, the Evaluation Result summary will be in the follow format:\n",
    "\n",
    "![Validate Result Summary](formatter_html_images/sample-report-evaluation-result-summary.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6: Generate the report\n",
    "\n",
    "At any moment, you may call `generate` with `writer` object to compile the report. The program will put all the contents added to report section (`overview` and `content`) and create content table (if enabled).  \n",
    "\n",
    "Below is sample to generate report in PDF format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report generated : /Users/i062308/Development/Explainable_AI/tutorials/formatter/hypertext_markup/sample_output/sample-report-final-with-summary.html\n"
     ]
    }
   ],
   "source": [
    "from xai.formatter import HtmlWriter\n",
    "report.generate(writer=HtmlWriter(name='sample-report-final-with-summary', path='./sample_output'))\n",
    "print(\"report generated : %s/sample_output/sample-report-final-with-summary.html\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report generated : /Users/i062308/Development/Explainable_AI/tutorials/formatter/hypertext_markup/sample_output/sample-report-final-with-summary-2.pdf\n"
     ]
    }
   ],
   "source": [
    "from xai.formatter import PdfWriter\n",
    "report.generate(writer=PdfWriter(name='sample-report-final-with-summary-2', path='./sample_output'))\n",
    "print(\"report generated : %s/sample_output/sample-report-final-with-summary-2.pdf\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
