{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME Text Explainer via XAI\n",
    "\n",
    "This tutorial demonstrates how to generate explanations using LIME's text explainer implemented by the Contextual AI library. Much of the tutorial overlaps with what is covered in the [LIME tabular tutorial](lime_tabular_explainer.ipynb). To recap, the main steps for generating explanations are:\n",
    "\n",
    "1. Get an explainer via the `ExplainerFactory` class\n",
    "2. Build the text explainer\n",
    "3. Call `explain_instance`\n",
    "\n",
    "\n",
    "## Credits\n",
    "1. Pramodh, Manduri <manduri.pramodh@sap.com>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some auxiliary imports for the tutorial\n",
    "import pprint\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(123456)\n",
    "\n",
    "# Set the path so that we can import ExplainerFactory\n",
    "sys.path.append('../../../')\n",
    "\n",
    "# Main Contextual AI imports\n",
    "import xai\n",
    "from xai.explainer import ExplainerFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load dataset and train a model\n",
    "\n",
    "In this tutorial, we rely on the 20newsgroups text dataset, which can be loaded via sklearn's dataset utility. Documentation on the dataset itself can be found [here](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html). To keep things simple, we will extract data for 3 topics - baseball, Christianity, and medicine.\n",
    "\n",
    "Our target model is a multinomial Naive Bayes classifier, which we train using TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'filenames', 'target_names', 'target', 'DESCR']\n",
      "['rec.sport.baseball', 'sci.med', 'soc.religion.christian']\n",
      "[1 0 2 2 0 2 0 0 0 1]\n",
      "'Subsetting training sample to 200 to speed up.'\n",
      "'Classifier score: 0.9689336691855583'\n",
      "('Classifier predict func <bound method _BaseNB.predict_proba of '\n",
      " 'MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)>:')\n"
     ]
    }
   ],
   "source": [
    "# Train on a subset of categories\n",
    "\n",
    "categories = [\n",
    "    'rec.sport.baseball',\n",
    "    'soc.religion.christian',\n",
    "    'sci.med'\n",
    "]\n",
    "\n",
    "raw_train = datasets.fetch_20newsgroups(subset='train', categories=categories)\n",
    "print(list(raw_train.keys()))\n",
    "print(raw_train.target_names)\n",
    "print(raw_train.target[:10])\n",
    "raw_test = datasets.fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "X_train = raw_train.data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "y_train = raw_train.target\n",
    "\n",
    "X_test_vec = vectorizer.transform(raw_test.data)\n",
    "y_test = raw_test.target\n",
    "\n",
    "clf = MultinomialNB(alpha=0.1)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "limit_size=200\n",
    "pprint('Subsetting training sample to %s to speed up.' % limit_size)\n",
    "X_train = X_train[:limit_size]\n",
    "pprint('Classifier score: %s' % clf.score(X_test_vec, y_test))\n",
    "pprint('Classifier predict func %s:' % clf.predict_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Instantiate the explainer\n",
    "\n",
    "Here, we will use the LIME Text Explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _BaseNB.predict_proba of MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer = ExplainerFactory.get_explainer(domain=xai.DOMAIN.TEXT)\n",
    "clf.predict_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build the explainer\n",
    "\n",
    "This initializes the underlying explainer object. We provide the `explain_instance` method below with the raw text - LIME's text explainer algorithm will conduct its own preprocessing in order to generate interpretable representations of the data. Hence we must define a custom `predict_fn` which takes a raw piece of text, vectorizes it via a pre-trained TF-IDF vectorizer, and passes the vector into the trained Naive Bayes model to generate class probabilities. LIME uses `predict_fn` to query our Naive Bayes model in order to learn its behavior around the provided data instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(instance):\n",
    "    vec = vectorizer.transform(instance)\n",
    "    return clf.predict_proba(vec)\n",
    "\n",
    "explainer.build_explainer(predict_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Report for Lime Text Explainer',\n",
       " 'overview': True,\n",
       " 'content_table': True,\n",
       " 'contents': [{'title': 'Model Interpreter Text Explainer',\n",
       "   'desc': 'This section provides the Interpretation of model',\n",
       "   'sections': [{'title': 'Model Interpreter Analysis ',\n",
       "     'desc': 'Model and train data from 20 News Group',\n",
       "     'component': {'_comment': 'refer to document section xxxx',\n",
       "      'class': 'ModelInterpreter',\n",
       "      'attr': {'domain': 'text',\n",
       "       'method': 'lime',\n",
       "       'mode': 'classification',\n",
       "       'train_data': 'var:X_train',\n",
       "       'labels': 'var:y_train',\n",
       "       'predict_func': 'var:clf_fn',\n",
       "       'target_names': 'var:target_names_list',\n",
       "       'model_interpret_stats_type': 'top_k',\n",
       "       'model_interpret_k_value': 5,\n",
       "       'model_interpret_top_value': 15,\n",
       "       'num_of_class': 1,\n",
       "       'valid_x': 'var:X_test',\n",
       "       'valid_y': 'var:y_test',\n",
       "       'error_analysis_stats_type': 'average_score',\n",
       "       'error_analysis_k_value': 5,\n",
       "       'error_analysis_top_value': 15}}}]}],\n",
       " 'writers': [{'class': 'Pdf',\n",
       "   'attr': {'name': '20newsgroup-clsssification-model-interpreter-report'}}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = clf\n",
    "feature_names = []\n",
    "clf_fn = predict_fn\n",
    "target_names_list = []\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from xai.compiler.base import Configuration, Controller\n",
    "json_config = 'lime-text-classification-model-interpreter.json'\n",
    "with open(json_config) as file:\n",
    "    config = json.load(file)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpret 100/200 samples\n",
      "Interpret 200/200 samples\n",
      "Warning: figure will exceed the page bottom, adding a new page.\n"
     ]
    }
   ],
   "source": [
    "controller = Controller(config=Configuration(config, locals()))\n",
    "controller.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('report generated : '\n",
      " '/Users/i062308/Development/Explainable_AI/tutorials/compiler/20newsgroup/20newsgroup-clsssification-model-interpreter-report.pdf')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'report generated : /Users/i062308/Development/Explainable_AI/tutorials/compiler/20newsgroup/20newsgroup-clsssification-model-interpreter-report.pdf'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pprint(\"report generated : %s/20newsgroup-clsssification-model-interpreter-report.pdf\" % os.getcwd())\n",
    "('report generated : '\n",
    " '/Users/i062308/Development/Explainable_AI/tutorials/compiler/20newsgroup/20newsgroup-clsssification-model-interpreter-report.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai-0.1.2-jupyter-py37",
   "language": "python",
   "name": "xai-0.1.2-jupyter-py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
