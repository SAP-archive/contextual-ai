{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Explainability Report with CashApp dataset using XAI\n",
    "\n",
    "This notebook demonstrates how to generate explanations report using complier implemented in the XAI library.\n",
    "\n",
    "\n",
    "## Steps\n",
    "1. Create required input from the Cashapp model_data pkl\n",
    "2. Evaluate the model performance with XAI report and generate a local explainer pkl\n",
    "3. Load the explainer pkl while inference and explain the instance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create required input from `sample_data.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ml-mkt-training/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/anaconda3/envs/ml-mkt-training/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.19.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "resource = joblib.load('_sample_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229953, 2)\n",
      "feature data dumped : /Users/i309943/workspace/Explainable_AI/tutorials/compiler/cashapp/train_data.csv\n",
      "(229953,)\n",
      "label dumped : /Users/i309943/workspace/Explainable_AI/tutorials/compiler/cashapp/y_true.csv\n",
      "(229953, 3)\n",
      "all data dumped : /Users/i309943/workspace/Explainable_AI/tutorials/compiler/cashapp/data.csv\n"
     ]
    }
   ],
   "source": [
    "training_data = resource['training_data']\n",
    "print(training_data.shape)\n",
    "training_data.to_csv('train_data.csv',index=False)\n",
    "print(\"feature data dumped : %s/train_data.csv\" % os.getcwd())\n",
    "\n",
    "training_label = resource['training_labels']\n",
    "training_label = np.array(training_label)\n",
    "print(training_label.shape)\n",
    "np.savetxt('y_true.csv',training_label,delimiter=',')\n",
    "print(\"label dumped : %s/y_true.csv\" % os.getcwd())\n",
    "\n",
    "all_data = deepcopy(training_data)\n",
    "all_data['matching'] = training_label\n",
    "print(all_data.shape)\n",
    "all_data.to_csv('data.csv',index=False)\n",
    "print(\"all data dumped : %s/data.csv\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Load Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_meta dumped : /Users/i309943/workspace/Explainable_AI/tutorials/compiler/cashapp/feature_meta.json\n",
      "class_label dumped : /Users/i309943/workspace/Explainable_AI/tutorials/compiler/cashapp/labels.json\n"
     ]
    }
   ],
   "source": [
    "feature_names = list(resource['feature_names'])\n",
    "categorical_features = list(resource['categorical_features'])\n",
    "categorical_names = dict(resource['categorical_names'])\n",
    "class_names = list(resource['class_names'])\n",
    "\n",
    "meta_data = dict()\n",
    "meta_data['class_names'] = class_names\n",
    "feature_meta = []\n",
    "for idx,feature_name in enumerate(feature_names):\n",
    "    if idx not in categorical_features:\n",
    "        feature_meta.append({'name':feature_name, 'type':'numerical'})\n",
    "    else:\n",
    "        if idx in categorical_names.keys():\n",
    "            feature_meta.append({'name':feature_name, \n",
    "                                 'type':'categorical', \n",
    "                                 'mapping':categorical_names[idx]})\n",
    "        else:\n",
    "            feature_meta.append({'name':feature_name, \n",
    "                                 'type':'categorical'})\n",
    "meta_data['feature_types'] = feature_meta\n",
    "\n",
    "import json\n",
    "with open('feature_meta.json','w') as f:\n",
    "    json.dump(meta_data,f)\n",
    "    print(\"feature_meta dumped : %s/feature_meta.json\" % os.getcwd())\n",
    "\n",
    "with open('labels.json','w') as f:\n",
    "    json.dump(class_names, f)\n",
    "    print(\"class_label dumped : %s/labels.json\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=None, colsample_bytree=1, gamma=1.0,\n",
      "              learning_rate=0.2, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=nan, n_estimators=100, n_jobs=1,\n",
      "              nthread=1, objective='multi:softprob', random_state=97,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=True, subsample=1, verbosity=None)\n",
      "model dumped : /Users/i309943/workspace/Explainable_AI/tutorials/compiler/cashapp/model.pkl\n",
      "function call dumped : /Users/i309943/workspace/Explainable_AI/tutorials/compiler/cashapp/func.pkl\n"
     ]
    }
   ],
   "source": [
    "model = resource['model_instance']\n",
    "print(model)\n",
    "with open('model.pkl','wb') as f:\n",
    "    pickle.dump(model,f)\n",
    "    print(\"model dumped : %s/model.pkl\" % os.getcwd())\n",
    "\n",
    "with open('func.pkl', 'wb') as func_pkl:\n",
    "    def predict_fn(x):\n",
    "        return model.predict_proba(\n",
    "            pd.DataFrame(x, columns=feature_names)).astype(float)\n",
    "    pickle.dump(predict_fn,func_pkl)\n",
    "    print(\"function call dumped : %s/func.pkl\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Perform Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_conf dumped : /Users/i309943/workspace/Explainable_AI/tutorials/compiler/cashapp/y_conf.csv\n"
     ]
    }
   ],
   "source": [
    "y_conf = model.predict_proba(training_data)\n",
    "np.savetxt(\"y_conf.csv\", y_conf, delimiter=\",\")\n",
    "print(\"y_conf dumped : %s/y_conf.csv\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Involve XAI complier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "sys.path.append('../../../')\n",
    "from xai.compiler.base import Configuration, Controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Specify config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_config = 'basic-report-explainer.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2  Initial compiler controller with config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content_table': True,\n",
      " 'contents': [{'desc': 'This section summarized the training performance',\n",
      "               'sections': [{'component': {'attr': {'labels_file': 'labels.json',\n",
      "                                                    'y_pred_file': 'y_conf.csv',\n",
      "                                                    'y_true_file': 'y_true.csv'},\n",
      "                                           'class': 'ClassificationEvaluationResult',\n",
      "                                           'module': 'compiler',\n",
      "                                           'package': 'xai'},\n",
      "                             'title': 'Training Result'}],\n",
      "               'title': 'Training Result'},\n",
      "              {'desc': 'This section provides the analysis on feature',\n",
      "               'sections': [{'component': {'_comment': 'refer to document '\n",
      "                                                       'section xxxx',\n",
      "                                           'attr': {'method': 'shap',\n",
      "                                                    'train_data': 'train_data.csv',\n",
      "                                                    'trained_model': 'model.pkl'},\n",
      "                                           'class': 'FeatureImportanceRanking'},\n",
      "                             'title': 'Feature Importance Ranking'}],\n",
      "               'title': 'Feature Importance Analysis'},\n",
      "              {'desc': 'This section provides the analysis on data',\n",
      "               'sections': [{'component': {'_comment': 'refer to document '\n",
      "                                                       'section xxxx',\n",
      "                                           'attr': {'data': 'data.csv',\n",
      "                                                    'label': 'matching'},\n",
      "                                           'class': 'DataStatisticsAnalysis'},\n",
      "                             'title': 'Simple Data Statistic'}],\n",
      "               'title': 'Data Statistics Analysis'},\n",
      "              {'desc': 'This section provides a model-agnostic explainer',\n",
      "               'sections': [{'component': {'attr': {'domain': 'tabular',\n",
      "                                                    'feature_meta': 'feature_meta.json',\n",
      "                                                    'method': 'lime',\n",
      "                                                    'num_features': 5,\n",
      "                                                    'predict_func': 'func.pkl',\n",
      "                                                    'train_data': 'train_data.csv'},\n",
      "                                           'class': 'ModelAgnosticExplainer',\n",
      "                                           'module': 'compiler',\n",
      "                                           'package': 'xai'},\n",
      "                             'title': 'Result'}],\n",
      "               'title': 'Model-Agnostic Explainer'}],\n",
      " 'name': 'Report for CashApp Dataset',\n",
      " 'overview': True,\n",
      " 'writers': [{'attr': {'name': 'cashapp-basic-report'}, 'class': 'Pdf'}]}\n"
     ]
    }
   ],
   "source": [
    "controller = Controller(config=Configuration(json_config))\n",
    "pprint(controller.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2  Finally compiler render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../../xai/compiler/explainer.py:119: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  train_data = train_data.as_matrix()\n",
      "../../../xai/graphs/basic_graph.py:52: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations. \n",
      "  plt.tight_layout()\n",
      "../../../xai/graphs/graph_generator.py:355: UserWarning: Attempting to set identical left == right == 0 results in singular transformations; automatically expanding.\n",
      "  plt.xlim([0, xlimit])\n"
     ]
    }
   ],
   "source": [
    " controller.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report generated : /Users/i309943/workspace/Explainable_AI/tutorials/compiler/cashapp/cashapp-basic-report.pdf\n"
     ]
    }
   ],
   "source": [
    "print(\"report generated : %s/cashapp-basic-report.pdf\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explainer generated : /Users/i309943/workspace/Explainable_AI/tutorials/compiler/cashapp/explainer.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"explainer generated : %s/explainer.pkl\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'confidence': 0.999993085861206,\n",
      "     'explanation': [{'feature': 'NUMSUFFIXSAME:MEMOLINE:ACCOUNTINGDOCUMENT_TRUNCATED '\n",
      "                                 '> 0.00',\n",
      "                      'score': -0.13365043117719663},\n",
      "                     {'feature': 'WORDSAMESCORE:MEMOLINE:ORGANIZATIONBPNAME > '\n",
      "                                 '0.00',\n",
      "                      'score': -0.0012361622311423371}]},\n",
      " 2: {'confidence': 3.849634140351554e-06,\n",
      "     'explanation': [{'feature': 'WORDSAMESCORE:MEMOLINE:ORGANIZATIONBPNAME > '\n",
      "                                 '0.00',\n",
      "                      'score': 0.032739598722119255},\n",
      "                     {'feature': 'NUMSUFFIXSAME:MEMOLINE:ACCOUNTINGDOCUMENT_TRUNCATED '\n",
      "                                 '> 0.00',\n",
      "                      'score': 0.024314783489174884}]}}\n"
     ]
    }
   ],
   "source": [
    "import xai\n",
    "from xai.explainer.explainer_factory import ExplainerFactory\n",
    "from pprint import pprint\n",
    "\n",
    "explainer = ExplainerFactory.get_explainer(domain=xai.DOMAIN.TABULAR, algorithm=xai.ALG.LIME)\n",
    "explainer.load_explainer('explainer.pkl')\n",
    "explanations = explainer.explain_instance(instance=training_data.values[0,:],num_features=5)\n",
    "pprint(explanations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3(ml-mkt-training)",
   "language": "python",
   "name": "ml-mkt-training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
