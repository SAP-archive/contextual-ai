{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME Tabular Explainer via XAI\n",
    "\n",
    "This tutorial demonstrates how to generate explanations using LIME's tabular explainer implemented by the Contextual AI library.\n",
    "\n",
    "At a high level, explanations can be obtained from any Contextual AI explanation algorithm in 3 steps:\n",
    "\n",
    "1. Create an explainer via the `ExplainerFactory` class, which serves as the primary interface between the user and all Contextual AI-supported explanation algorithms\n",
    "2. Build the explainer by calling the `build_explainer` method (which is implemented by any Contextual AI explanation algorithm) and providing arguments that are specific to that algorithm\n",
    "3. Get explanations for some data instance by calling the `explain_instance` method (which is also common among all algorithms) and provoding arguments that are specific to that algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries\n",
    "\n",
    "`xai.explainer.ExplainerFactory` is the main class that users of Contextual AI interact with. `xai` contains some constants that are used to instantiate an `AbstractExplainer` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some auxiliary imports for the tutorial\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(123456)\n",
    "\n",
    "# Set the path so that we can import ExplainerFactory\n",
    "sys.path.append('../../')\n",
    "\n",
    "# Main Contextual AI imports\n",
    "import xai\n",
    "from xai.explainer import ExplainerFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train a model on a sample dataset\n",
    "\n",
    "We train a sample `RandomForestClassifier` model on the Wisconsin breast cancer dataset, a sample binary classification problem that is provided by scikit-learn (details can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i330688/venv_xai/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset and prepare training and test sets\n",
    "raw_data = datasets.load_breast_cancer()\n",
    "X, y = raw_data['data'], raw_data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate a classifier, train, and evaluate on test set\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Instantiate the explainer\n",
    "\n",
    "This is where we instantiate the Contextual AI explainer. This `ExplainerFactory` class is in charge of loading a particular explanation algorithm. The user is required to provide one argument - the `domain`, which indicates the domain of the training data (e.g. `tabular` or `text`). The available domains can be found in `xai.DOMAIN`. Users can also select a particular explainer algorithm by providing the algorithm's name (registered in `xai.ALG`) to the `algorithm` parameter. If this argument is not provided, the `ExplainerFactory.get_explainer` method defaults to a pre-set algorithm for that domain which can be found in `xai/explainer/config.py`. \n",
    "\n",
    "We want to load the `LimeTabularExplainer`, so we provide `xai.DOMAIN.TABULAR` as the argument to `domain` and `xai.ALG.LIME` as the argument to `algorithm`. Note that `xai.ALG.LIME` is the default tabular explanation algorithm; hence this also works:\n",
    "\n",
    "```python\n",
    "explainer = ExplainerFactory.get_explainer(domain=xai.DOMAIN.TABULAR)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate LimeTabularExplainer via the Explainer interface\n",
    "explainer = ExplainerFactory.get_explainer(domain=xai.DOMAIN.TABULAR, algorithm=xai.ALG.LIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build the explainer\n",
    "\n",
    "`build_explainer` calls the explanation algorithms initialization routine, which can include things like setting parameters or a pre-training loop. The `LimeTabularExplainer` requires the following parameters:\n",
    "\n",
    "* training_data (np.ndarray): 2d Numpy array representing the training data\n",
    "    (or some representative subset) (**required**)\n",
    "* mode (str): Whether the problem is 'classification' or 'regression' (**required**)\n",
    "* predict_fn (function): A function that wraps the target model's prediction function - it takes in a 1D numpy array and outputs a vector of probabilities which should sum to 1 (**required**) \n",
    "\n",
    "\n",
    "Here are some other optional parameters:\n",
    "* training_labels (list): Training labels, which can be used by the continuous feature\n",
    "    discretizer\n",
    "* feature_names (list): The names of the columns of the training data\n",
    "* categorical_features (list): Integer list indicating the indices of categorical features\n",
    "* dict_categorical_mapping (dict): Mapping of integer index of categorical feature\n",
    "    (same as from categorical_features) to a list of values for that column.\n",
    "    So dict_categorical_mapping[x][y] is the yth value of column x.\n",
    "* kernel_width (float): Width of the exponential kernel used in the LIME loss function\n",
    "* verbose (bool): Control verbosity. If true, local prediction values of the LIME model\n",
    "    are printed\n",
    "* class_names (list): Class names (positional index corresponding to class index)\n",
    "* feature_selection (str): Feature selection method. See original docs for more details\n",
    "* discretize_continuous (True): Whether to discretize non-categorical features\n",
    "* discretizer (str): Type of discretization. See original docs for more details\n",
    "* sample_around_instance (True): if True, will sample continuous features\n",
    "    in perturbed samples from a normal centered at the instance\n",
    "    being explained. Otherwise, the normal is centered on the mean\n",
    "    of the feature data.\n",
    "* random_state (int): The random seed to generate random numbers during training\n",
    "\n",
    "In this particular example, we pass the `RandomForestClassifier`'s `predict_proba` function to `predict_fn` and get explanations for the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.build_explainer(\n",
    "    training_data=X_train,\n",
    "    training_labels=y_train,\n",
    "    mode=xai.MODE.CLASSIFICATION,\n",
    "    predict_fn=clf.predict_proba,\n",
    "    feature_names=raw_data['feature_names'],\n",
    "    class_names=list(raw_data['target_names'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Generate some explanations\n",
    "\n",
    "Once we build the explainer, we can start generating some explanations via the `explain_instance` method. The `LimeTabularExplainer` expects several things, like:\n",
    "* instance (np.ndarray): A 1D numpy array corresponding to a row/single example (**required**)\n",
    "\n",
    "You can also pass the following:\n",
    "\n",
    "* labels (list): The list of class indexes to produce explanations for\n",
    "* top_labels (int): If not None, this overwrites labels and the explainer instead produces\n",
    "    explanations for the top k classes\n",
    "* num_features (int): Number of features to include in an explanation\n",
    "* num_samples (int): The number of perturbed samples to train the LIME model with\n",
    "* distance_metric (str): The distance metric to use for weighting the loss function\n",
    "\n",
    "\n",
    "We restrict explanations to 10 features (meaning only 10 features will have scores attached to them). The output of `explain_instance` is a dictionary that maps each class to two things - the confidence of model and a list of explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'explanation': [{'feature': 'worst perimeter <= 83.79',\n",
      "                      'score': -0.10193695487658752},\n",
      "                     {'feature': 'worst area <= 509.25',\n",
      "                      'score': -0.09601666088375639},\n",
      "                     {'feature': 'worst radius <= 12.93',\n",
      "                      'score': -0.06025582708518221},\n",
      "                     {'feature': 'mean area <= 419.25',\n",
      "                      'score': -0.056302517885391166},\n",
      "                     {'feature': 'worst texture <= 21.41',\n",
      "                      'score': -0.05509499962470648}],\n",
      "     'prediction': 0.0},\n",
      " 1: {'explanation': [{'feature': 'worst perimeter <= 83.79',\n",
      "                      'score': 0.10193695487658752},\n",
      "                     {'feature': 'worst area <= 509.25',\n",
      "                      'score': 0.0960166608837564},\n",
      "                     {'feature': 'worst radius <= 12.93',\n",
      "                      'score': 0.06025582708518222},\n",
      "                     {'feature': 'mean area <= 419.25',\n",
      "                      'score': 0.05630251788539119},\n",
      "                     {'feature': 'worst texture <= 21.41',\n",
      "                      'score': 0.05509499962470641}],\n",
      "     'prediction': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "exp = explainer.explain_instance(\n",
    "    instance=X_test[0],\n",
    "    top_labels=2,\n",
    "    num_features=5)\n",
    "\n",
    "pprint(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Save and load the explainer\n",
    "\n",
    "Finally, every Contextual AI explainer supports saving and loading functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the explainer somewhere\n",
    "\n",
    "explainer.save_explainer('artefacts/lime_tabular.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'explanation': [{'feature': 'worst perimeter <= 83.79',\n",
      "                      'score': -0.09985606175737251},\n",
      "                     {'feature': 'worst area <= 509.25',\n",
      "                      'score': -0.08623375147255567},\n",
      "                     {'feature': 'mean area <= 419.25',\n",
      "                      'score': -0.07671371631709668},\n",
      "                     {'feature': 'worst radius <= 12.93',\n",
      "                      'score': -0.06861610584095608},\n",
      "                     {'feature': 'worst texture <= 21.41',\n",
      "                      'score': -0.05078617133441289}],\n",
      "     'prediction': 0.0},\n",
      " 1: {'explanation': [{'feature': 'worst perimeter <= 83.79',\n",
      "                      'score': 0.09985606175737251},\n",
      "                     {'feature': 'worst area <= 509.25',\n",
      "                      'score': 0.08623375147255567},\n",
      "                     {'feature': 'mean area <= 419.25',\n",
      "                      'score': 0.0767137163170967},\n",
      "                     {'feature': 'worst radius <= 12.93',\n",
      "                      'score': 0.0686161058409561},\n",
      "                     {'feature': 'worst texture <= 21.41',\n",
      "                      'score': 0.05078617133441288}],\n",
      "     'prediction': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "# Load the saved explainer in a new Explainer instance\n",
    "\n",
    "new_explainer = ExplainerFactory.get_explainer(domain=xai.DOMAIN.TABULAR, algorithm=xai.ALG.LIME)\n",
    "new_explainer.load_explainer('artefacts/lime_tabular.pkl')\n",
    "\n",
    "exp = new_explainer.explain_instance(\n",
    "    instance=X_test[0],\n",
    "    top_labels=2,\n",
    "    num_features=5)\n",
    "\n",
    "pprint(exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
