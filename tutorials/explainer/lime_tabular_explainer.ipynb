{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME Tabular Explainer via XAI\n",
    "\n",
    "This tutorial demonstrates how to generate explanations using LIME's tabular explainer implemented by the XAI library.\n",
    "\n",
    "At a high level, explanations can be obtained from any XAI explanation algorithm in 3 steps:\n",
    "\n",
    "1. Instantiate the Explainer class, which serves as an interface between the user and each explanation algorithm\n",
    "2. Build the explainer by calling the `build_explainer` method (which is implemented by any XAI explanation algorithm) and providing arguments that are specific to that algorithm\n",
    "3. Get explanations for some data instance by calling the `explain_instance` method (which is also common among all algorithms) and provoding arguments that are specific to that algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries\n",
    "\n",
    "`xai.explainer.Explainer` is the main class that users of XAI interact with. `xai` contains some constants that are used to instantiate an `Explainer` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i330688/venv_xai/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/i330688/venv_xai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Some auxiliary imports for the tutorial\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(123456)\n",
    "\n",
    "# Set the path so that we can import the Explainer\n",
    "sys.path.append('../../')\n",
    "\n",
    "# Main XAI imports\n",
    "import xai\n",
    "from xai.explainer import Explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train a model on a sample dataset\n",
    "\n",
    "We train a sample `RandomForestClassifier` model on the Wisconsin breast cancer dataset, a sample binary classification problem that is provided by scikit-learn (details can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset and prepare training and test sets\n",
    "raw_data = datasets.load_breast_cancer()\n",
    "X, y = raw_data['data'], raw_data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate a classifier, train, and evaluate on test set\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Instantiate the explainer\n",
    "\n",
    "This is where we instantiate the XAI `Explainer`. This class is in charge of loading a particular explanation algorithm and serving as its interface to the user. The user is required to provide one argument - the `domain`, which indicates the domain of the training data (e.g. `tabular` or `text`). The available domains can be found in `xai.DOMAIN`. Users can also select a particular explainer algorithm by providing the algorithm's name (registered in `xai.ALG`) to the `algorithm` parameter. If this argument is not provided, the `Explainer` class defaults to a pre-set algorithm for that domain which can be found in `xai/explainer/config.py`. \n",
    "\n",
    "We want to load the `LimeTabularExplainer`, so we provide `xai.DOMAIN.TABULAR` as the argument to `domain` and `xai.ALG.LIME` as the argument to `algorithm`. Note that `xai.ALG.LIME` is the default tabular explanation algorithm; hence this also works:\n",
    "\n",
    "```python\n",
    "explainer = Explainer(domain=xai.DOMAIN.TABULAR)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate LimeTabularExplainer via the Explainer interface\n",
    "explainer = Explainer(domain=xai.DOMAIN.TABULAR, algorithm=xai.ALG.LIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build the explainer\n",
    "\n",
    "`build_explainer` calls the explanation algorithms initialization routine, which can include things like setting parameters or a pre-training loop. The `LimeTabularExplainer` requires the following parameters:\n",
    "\n",
    "* training_data (np.ndarray): 2d Numpy array representing the training data\n",
    "    (or some representative subset) (**required**)\n",
    "* mode (str): Whether the problem is 'classification' or 'regression' (**required**)\n",
    "* predict_fn (function): A function that wraps the target model's prediction function - it takes in a 1D numpy array and outputs a vector of probabilities which should sum to 1 (**required**) \n",
    "\n",
    "\n",
    "Here are some other optional parameters:\n",
    "* training_labels (list): Training labels, which can be used by the continuous feature\n",
    "    discretizer\n",
    "* column_names (list): The names of the columns of the training data\n",
    "* categorical_features (list): Integer list indicating the indices of categorical features\n",
    "* dict_categorical_mapping (dict): Mapping of integer index of categorical feature\n",
    "    (same as from categorical_features) to a list of values for that column.\n",
    "    So dict_categorical_mapping[x][y] is the yth value of column x.\n",
    "* kernel_width (float): Width of the exponential kernel used in the LIME loss function\n",
    "* verbose (bool): Control verbosity. If true, local prediction values of the LIME model\n",
    "    are printed\n",
    "* class_names (list): Class names (positional index corresponding to class index)\n",
    "* feature_selection (str): Feature selection method. See original docs for more details\n",
    "* discretize_continuous (True): Whether to discretize non-categorical features\n",
    "* discretizer (str): Type of discretization. See original docs for more details\n",
    "* sample_around_instance (True): if True, will sample continuous features\n",
    "    in perturbed samples from a normal centered at the instance\n",
    "    being explained. Otherwise, the normal is centered on the mean\n",
    "    of the feature data.\n",
    "* random_state (int): The random seed to generate random numbers during training\n",
    "\n",
    "In this particular example, we pass the `RandomForestClassifier`'s `predict_proba` function to `predict_fn` and get explanations for the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.build_explainer(\n",
    "    training_data=X_train,\n",
    "    training_labels=y_train,\n",
    "    mode='classification',\n",
    "    predict_fn=clf.predict_proba,\n",
    "    column_names=raw_data['feature_names'],\n",
    "    class_names=list(raw_data['target_names'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Generate some explanations\n",
    "\n",
    "Once we build the explainer, we can start generating some explanations via the `explain_instance` method. The `LimeTabularExplainer` expects several things, like:\n",
    "* instance (np.ndarray): A 1D numpy array corresponding to a row/single example (**required**)\n",
    "\n",
    "You can also pass the following:\n",
    "\n",
    "* labels (list): The list of class indexes to produce explanations for\n",
    "* top_labels (int): If not None, this overwrites labels and the explainer instead produces\n",
    "    explanations for the top k classes\n",
    "* num_features (int): Number of features to include in an explanation\n",
    "* num_samples (int): The number of perturbed samples to train the LIME model with\n",
    "* distance_metric (str): The distance metric to use for weighting the loss function\n",
    "\n",
    "\n",
    "We restrict explanations to 10 features (meaning only 10 features will have scores attached to them). The output of `explain_instance` is a dictionary that maps each class to two things - the confidence of model and a list of explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'confidence': 0.0,\n",
      "     'explanation': [{'feature': 'worst perimeter <= 83.79',\n",
      "                      'score': -0.10275161028167702},\n",
      "                     {'feature': 'worst area <= 509.25',\n",
      "                      'score': -0.09479442043867894},\n",
      "                     {'feature': 'worst radius <= 12.93',\n",
      "                      'score': -0.060148145614287524},\n",
      "                     {'feature': 'worst texture <= 21.41',\n",
      "                      'score': -0.057578312942073995},\n",
      "                     {'feature': 'mean area <= 419.25',\n",
      "                      'score': -0.05598211138713413},\n",
      "                     {'feature': 'worst concave points <= 0.06',\n",
      "                      'score': -0.05063258480760927},\n",
      "                     {'feature': 'mean texture <= 16.34',\n",
      "                      'score': -0.042193966171229905},\n",
      "                     {'feature': 'mean concavity <= 0.03',\n",
      "                      'score': -0.028153608385264327},\n",
      "                     {'feature': 'area error <= 18.17',\n",
      "                      'score': -0.027911303586217028},\n",
      "                     {'feature': 'worst compactness <= 0.15',\n",
      "                      'score': -0.024483076857988333}]},\n",
      " 1: {'confidence': 1.0,\n",
      "     'explanation': [{'feature': 'worst perimeter <= 83.79',\n",
      "                      'score': 0.10275161028167702},\n",
      "                     {'feature': 'worst area <= 509.25',\n",
      "                      'score': 0.09479442043867897},\n",
      "                     {'feature': 'worst radius <= 12.93',\n",
      "                      'score': 0.06014814561428753},\n",
      "                     {'feature': 'worst texture <= 21.41',\n",
      "                      'score': 0.057578312942073995},\n",
      "                     {'feature': 'mean area <= 419.25',\n",
      "                      'score': 0.05598211138713414},\n",
      "                     {'feature': 'worst concave points <= 0.06',\n",
      "                      'score': 0.05063258480760927},\n",
      "                     {'feature': 'mean texture <= 16.34',\n",
      "                      'score': 0.0421939661712299},\n",
      "                     {'feature': 'mean concavity <= 0.03',\n",
      "                      'score': 0.028153608385264303},\n",
      "                     {'feature': 'area error <= 18.17',\n",
      "                      'score': 0.027911303586217028},\n",
      "                     {'feature': 'worst compactness <= 0.15',\n",
      "                      'score': 0.024483076857988346}]}}\n"
     ]
    }
   ],
   "source": [
    "exp = explainer.explain_instance(\n",
    "    instance=X_test[0],\n",
    "    top_labels=2,\n",
    "    num_features=10)\n",
    "\n",
    "pprint(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Save and load the explainer\n",
    "\n",
    "Finally, every XAI explainer supports saving and loading functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the explainer somewhere\n",
    "\n",
    "explainer.save_explainer('artefacts/lime_tabular.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'confidence': 0.0,\n",
      "     'explanation': [{'feature': 'worst perimeter <= 83.79',\n",
      "                      'score': -0.0988888637468886},\n",
      "                     {'feature': 'worst area <= 509.25',\n",
      "                      'score': -0.08697607214733627},\n",
      "                     {'feature': 'mean area <= 419.25',\n",
      "                      'score': -0.07593313480546983},\n",
      "                     {'feature': 'worst radius <= 12.93',\n",
      "                      'score': -0.06743098333423715},\n",
      "                     {'feature': 'worst texture <= 21.41',\n",
      "                      'score': -0.05073096916988603},\n",
      "                     {'feature': 'mean texture <= 16.34',\n",
      "                      'score': -0.03796017799565063},\n",
      "                     {'feature': 'worst concave points <= 0.06',\n",
      "                      'score': -0.035642798244049576},\n",
      "                     {'feature': 'area error <= 18.17',\n",
      "                      'score': -0.02973519533368258},\n",
      "                     {'feature': '0.12 < worst smoothness <= 0.13',\n",
      "                      'score': -0.027025385756363693},\n",
      "                     {'feature': 'worst concavity <= 0.11',\n",
      "                      'score': -0.019772658434194377}]},\n",
      " 1: {'confidence': 1.0,\n",
      "     'explanation': [{'feature': 'worst perimeter <= 83.79',\n",
      "                      'score': 0.0988888637468886},\n",
      "                     {'feature': 'worst area <= 509.25',\n",
      "                      'score': 0.08697607214733628},\n",
      "                     {'feature': 'mean area <= 419.25',\n",
      "                      'score': 0.07593313480546983},\n",
      "                     {'feature': 'worst radius <= 12.93',\n",
      "                      'score': 0.06743098333423717},\n",
      "                     {'feature': 'worst texture <= 21.41',\n",
      "                      'score': 0.05073096916988604},\n",
      "                     {'feature': 'mean texture <= 16.34',\n",
      "                      'score': 0.037960177995650615},\n",
      "                     {'feature': 'worst concave points <= 0.06',\n",
      "                      'score': 0.03564279824404958},\n",
      "                     {'feature': 'area error <= 18.17',\n",
      "                      'score': 0.029735195333682587},\n",
      "                     {'feature': '0.12 < worst smoothness <= 0.13',\n",
      "                      'score': 0.027025385756363676},\n",
      "                     {'feature': 'worst concavity <= 0.11',\n",
      "                      'score': 0.01977265843419438}]}}\n"
     ]
    }
   ],
   "source": [
    "# Load the saved explainer in a new Explainer instance\n",
    "\n",
    "new_explainer = Explainer(domain=xai.DOMAIN.TABULAR, algorithm=xai.ALG.LIME)\n",
    "new_explainer.load_explainer('artefacts/lime_tabular.pkl')\n",
    "\n",
    "exp = new_explainer.explain_instance(\n",
    "    instance=X_test[0],\n",
    "    top_labels=2,\n",
    "    num_features=10)\n",
    "\n",
    "pprint(exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
