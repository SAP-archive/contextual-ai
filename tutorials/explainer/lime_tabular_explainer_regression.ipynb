{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME Tabular Explainer via XAI for Regression\n",
    "\n",
    "This tutorial demonstrates how to generate explanations using LIME's tabular explainer implemented by the XAI library for a regression task.\n",
    "\n",
    "At a high level, explanations can be obtained from any XAI explanation algorithm in 3 steps:\n",
    "\n",
    "1. Create an explainer via the `ExplainerFactory` class, which serves as the primary interface between the user and all XAI-supported explanation algorithms\n",
    "2. Build the explainer by calling the `build_explainer` method (which is implemented by any XAI explanation algorithm) and providing arguments that are specific to that algorithm\n",
    "3. Get explanations for some data instance by calling the `explain_instance` method (which is also common among all algorithms) and provoding arguments that are specific to that algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries\n",
    "\n",
    "`xai.explainer.ExplainerFactory` is the main class that users of XAI interact with. `xai` contains some constants that are used to instantiate an `AbstractExplainer` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some auxiliary imports for the tutorial\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(123456)\n",
    "\n",
    "# Set the path so that we can import ExplainerFactory\n",
    "sys.path.append('../..')\n",
    "\n",
    "# Main XAI imports\n",
    "import xai\n",
    "from xai.explainer import ExplainerFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train a model on a sample dataset\n",
    "\n",
    "We train a sample `RandomForestRegressor` model on the Boston housing dataset, a sample regression problem that is provided by scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSError 9.785803784803988\n"
     ]
    }
   ],
   "source": [
    "raw_data = datasets.load_boston()\n",
    "X, y = raw_data['data'], raw_data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate a classifier, train, and evaluate on test set\n",
    "clf = RandomForestRegressor(n_estimators=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Random Forest MSError', np.mean((clf.predict(X_test) - y_test) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Instantiate the explainer\n",
    "\n",
    "This is where we instantiate the XAI explainer. This `ExplainerFactory` class is in charge of loading a particular explanation algorithm. The user is required to provide one argument - the `domain`, which indicates the domain of the training data (e.g. `tabular` or `text`). The available domains can be found in `xai.DOMAIN`. Users can also select a particular explainer algorithm by providing the algorithm's name (registered in `xai.ALG`) to the `algorithm` parameter. If this argument is not provided, the `ExplainerFactory.get_explainer` method defaults to a pre-set algorithm for that domain which can be found in `xai/explainer/config.py`. \n",
    "\n",
    "We want to load the `LimeTabularExplainer`, so we provide `xai.DOMAIN.TABULAR` as the argument to `domain` and `xai.ALG.LIME` as the argument to `algorithm`. Note that `xai.ALG.LIME` is the default tabular explanation algorithm; hence this also works:\n",
    "\n",
    "```python\n",
    "explainer = ExplainerFactory.get_explainer(domain=xai.DOMAIN.TABULAR)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate LimeTabularExplainer via the Explainer interface\n",
    "explainer = ExplainerFactory.get_explainer(domain=xai.DOMAIN.TABULAR, \n",
    "                                           algorithm=xai.ALG.LIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build the explainer\n",
    "\n",
    "`build_explainer` calls the explanation algorithms initialization routine, which can include things like setting parameters or a pre-training loop. The `LimeTabularExplainer` requires the following parameters:\n",
    "\n",
    "* training_data (np.ndarray): 2d Numpy array representing the training data\n",
    "    (or some representative subset) (**required**)\n",
    "* mode (str): Whether the problem is 'classification' or 'regression' (**required**)\n",
    "* predict_fn (function): A function that wraps the target model's prediction function - it takes in a 1D numpy array and outputs a vector of probabilities which should sum to 1 (**required**) \n",
    "\n",
    "In this tutorial, we set mode to `xai.MODE.REGRESSION`. We also provide the following parameters:\n",
    "\n",
    "* training_labels (list): Training labels, which can be used by the continuous feature\n",
    "    discretizer\n",
    "* feature_names (list): The names of the columns of the training data\n",
    "* categorical_features (list): Integer list indicating the indices of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = np.argwhere(np.array([len(set(raw_data.data[:,x])) \n",
    "                                             for x in range(raw_data.data.shape[1])]) <= 10).flatten()\n",
    "\n",
    "explainer.build_explainer(\n",
    "    training_data=X_train,\n",
    "    training_labels=y_train,\n",
    "    mode=xai.MODE.REGRESSION,\n",
    "    predict_fn=clf.predict,\n",
    "    feature_names=raw_data['feature_names'],\n",
    "    categorical_features=categorical_features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Generate some explanations\n",
    "\n",
    "Once we build the explainer, we can start generating some explanations via the `explain_instance` method. The `LimeTabularExplainer` expects several things, like:\n",
    "* instance (np.ndarray): A 1D numpy array corresponding to a row/single example (**required**)\n",
    "\n",
    "You can also pass the following:\n",
    "\n",
    "* labels (list): The list of class indexes to produce explanations for\n",
    "* top_labels (int): If not None, this overwrites labels and the explainer instead produces\n",
    "    explanations for the top k classes\n",
    "* num_features (int): Number of features to include in an explanation\n",
    "* num_samples (int): The number of perturbed samples to train the LIME model with\n",
    "* distance_metric (str): The distance metric to use for weighting the loss function\n",
    "\n",
    "\n",
    "We restrict explanations to 10 features (meaning only 10 features will have scores attached to them). The output of `explain_instance` is a dictionary that maps each class to two things - the confidence of model and a list of explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'explanation': [{'feature': '7.17 < LSTAT <= 11.68',\n",
      "                  'score': 2.3211043718179445},\n",
      "                 {'feature': '6.19 < RM <= 6.63', 'score': -1.399854197466358},\n",
      "                 {'feature': 'PTRATIO <= 17.40', 'score': 0.5885472330074492},\n",
      "                 {'feature': 'DIS > 5.10', 'score': -0.5352117675978874},\n",
      "                 {'feature': 'RAD=4', 'score': -0.4687921251480069}],\n",
      " 'prediction': 25.04439999999986}\n"
     ]
    }
   ],
   "source": [
    "exp = explainer.explain_instance(\n",
    "    instance=X_test[1],\n",
    "    top_labels=2,\n",
    "    num_features=5)\n",
    "\n",
    "pprint(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Save and load the explainer\n",
    "\n",
    "Finally, every XAI explainer supports saving and loading functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the explainer somewhere\n",
    "\n",
    "explainer.save_explainer('artefacts/lime_tabular_regression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'explanation': [{'feature': 'LSTAT > 17.15', 'score': -6.056198593262318},\n",
      "                 {'feature': 'RM <= 5.88', 'score': -3.018462829585109},\n",
      "                 {'feature': 'DIS <= 2.06', 'score': 1.2463072456971418},\n",
      "                 {'feature': 'NOX > 0.64', 'score': -0.7486631874520833},\n",
      "                 {'feature': '77.95 < AGE <= 94.15',\n",
      "                  'score': -0.6001661104431496}],\n",
      " 'prediction': 8.738599999999975}\n"
     ]
    }
   ],
   "source": [
    "# Load the saved explainer in a new Explainer instance\n",
    "\n",
    "new_explainer = ExplainerFactory.get_explainer(domain=xai.DOMAIN.TABULAR, algorithm=xai.ALG.LIME)\n",
    "new_explainer.load_explainer('artefacts/lime_tabular_regression.pkl')\n",
    "\n",
    "exp = new_explainer.explain_instance(\n",
    "    instance=X_test[0],\n",
    "    top_labels=2,\n",
    "    num_features=5)\n",
    "\n",
    "pprint(exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
