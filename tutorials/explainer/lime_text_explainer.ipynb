{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME Text Explainer via XAI\n",
    "\n",
    "This tutorial demonstrates how to generate explanations using LIME's text explainer implemented by the Contextual AI library. Much of the tutorial overlaps with what is covered in the [LIME tabular tutorial](lime_tabular_explainer.ipynb). To recap, the main steps for generating explanations are:\n",
    "\n",
    "1. Get an explainer via the `ExplainerFactory` class\n",
    "2. Build the text explainer\n",
    "3. Call `explain_instance`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some auxiliary imports for the tutorial\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(123456)\n",
    "\n",
    "# Set the path so that we can import ExplainerFactory\n",
    "sys.path.append('../../')\n",
    "\n",
    "# Main Contextual AI imports\n",
    "import xai\n",
    "from xai.explainer import ExplainerFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load dataset and train a model\n",
    "\n",
    "In this tutorial, we rely on the 20newsgroups text dataset, which can be loaded via sklearn's dataset utility. Documentation on the dataset itself can be found [here](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html). To keep things simple, we will extract data for 3 topics - baseball, Christianity, and medicine.\n",
    "\n",
    "Our target model is a multinomial Naive Bayes classifier, which we train using TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'filenames', 'target_names', 'target', 'DESCR']\n",
      "['rec.sport.baseball', 'sci.med', 'soc.religion.christian']\n",
      "[1 0 2 2 0 2 0 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9689336691855583"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on a subset of categories\n",
    "\n",
    "categories = [\n",
    "    'rec.sport.baseball',\n",
    "    'soc.religion.christian',\n",
    "    'sci.med'\n",
    "]\n",
    "\n",
    "raw_train = datasets.fetch_20newsgroups(subset='train', categories=categories)\n",
    "print(list(raw_train.keys()))\n",
    "print(raw_train.target_names)\n",
    "print(raw_train.target[:10])\n",
    "raw_test = datasets.fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(raw_train.data)\n",
    "y_train = raw_train.target\n",
    "\n",
    "X_test = vectorizer.transform(raw_test.data)\n",
    "y_test = raw_test.target\n",
    "\n",
    "clf = MultinomialNB(alpha=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Instantiate the explainer\n",
    "\n",
    "Here, we will use the LIME Text Explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = ExplainerFactory.get_explainer(domain=xai.DOMAIN.TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build the explainer\n",
    "\n",
    "This initializes the underlying explainer object. We provide the `explain_instance` method below with the raw text - LIME's text explainer algorithm will conduct its own preprocessing in order to generate interpretable representations of the data. Hence we must define a custom `predict_fn` which takes a raw piece of text, vectorizes it via a pre-trained TF-IDF vectorizer, and passes the vector into the trained Naive Bayes model to generate class probabilities. LIME uses `predict_fn` to query our Naive Bayes model in order to learn its behavior around the provided data instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(instance):\n",
    "    vec = vectorizer.transform(instance)\n",
    "    return clf.predict_proba(vec)\n",
    "\n",
    "\n",
    "explainer.build_explainer(predict_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Generate some explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i330688/venv_xai/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label rec.sport.baseball 0\n",
      "{0: {'confidence': 0.9604247937223921,\n",
      "     'explanation': [{'feature': 'Mattingly', 'score': 0.1630204569197586},\n",
      "                     {'feature': 'njit', 'score': -0.05400846560032084},\n",
      "                     {'feature': 'Yankee', 'score': 0.047128435532711524},\n",
      "                     {'feature': 'Lurie', 'score': 0.0459271027896729},\n",
      "                     {'feature': 'PLAYERS', 'score': 0.045541508852427214},\n",
      "                     {'feature': 'tesla', 'score': -0.04552783302602691},\n",
      "                     {'feature': 'Allegheny', 'score': 0.0440014710417496},\n",
      "                     {'feature': 'luriem', 'score': 0.04385267215867704},\n",
      "                     {'feature': 'Liberalizer', 'score': 0.042445765884872304},\n",
      "                     {'feature': 'Don', 'score': -0.030393475108189762}]},\n",
      " 1: {'confidence': 0.015984823571617023,\n",
      "     'explanation': [{'feature': 'Mattingly', 'score': -0.05443408204951863},\n",
      "                     {'feature': 'alleg', 'score': -0.023071281337399444},\n",
      "                     {'feature': 'Yankee', 'score': -0.0204790656431549},\n",
      "                     {'feature': 'Allegheny', 'score': -0.019319586624860205},\n",
      "                     {'feature': 'game', 'score': -0.019075909341883114},\n",
      "                     {'feature': 'Lurie', 'score': -0.01823234234170473},\n",
      "                     {'feature': 'tesla', 'score': 0.016795268385738336},\n",
      "                     {'feature': '1993Apr21', 'score': 0.012968253445169269},\n",
      "                     {'feature': 'Don', 'score': 0.011628382538193854},\n",
      "                     {'feature': 'njit', 'score': 0.011514128262241137}]},\n",
      " 2: {'confidence': 0.02359038270598772,\n",
      "     'explanation': [{'feature': 'Mattingly', 'score': -0.11653224143274481},\n",
      "                     {'feature': 'njit', 'score': 0.036924001047734877},\n",
      "                     {'feature': 'PLAYERS', 'score': -0.034825273342100574},\n",
      "                     {'feature': 'Lurie', 'score': -0.03388829751366763},\n",
      "                     {'feature': 'Yankee', 'score': -0.033169483357673},\n",
      "                     {'feature': 'luriem', 'score': -0.032474210174719534},\n",
      "                     {'feature': 'Liberalizer', 'score': -0.03079880516104312},\n",
      "                     {'feature': 'Jesus', 'score': 0.027367258249072796},\n",
      "                     {'feature': 'tesla', 'score': 0.022433618170210407},\n",
      "                     {'feature': 'christ', 'score': 0.02164039206739657}]}}\n"
     ]
    }
   ],
   "source": [
    "exp = explainer.explain_instance(\n",
    "    labels=[0, 1, 2],\n",
    "    instance=raw_test.data[0],\n",
    "    num_features=10\n",
    ")\n",
    "\n",
    "print('Label', raw_train.target_names[raw_test.target[0]], raw_test.target[0])\n",
    "pprint(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with the LIME tabular explainer, the output of `explain_instance` is a JSON-compatible object where each class index maps to the target model's confidence and the corresponding explanations generated by LIME. For text, each feature is a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i330688/venv_xai/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label sci.med 1\n",
      "{0: {'confidence': 0.006374625691451515,\n",
      "     'explanation': [{'feature': 'pain', 'score': -0.027402611439935602},\n",
      "                     {'feature': 'sr', 'score': 0.026176880833875864},\n",
      "                     {'feature': 'ai', 'score': -0.023919836440025922},\n",
      "                     {'feature': 'Covington', 'score': -0.02087504251506631},\n",
      "                     {'feature': 'mcovingt', 'score': -0.02069997767962776}]},\n",
      " 1: {'confidence': 0.8824748491424798,\n",
      "     'explanation': [{'feature': 'hp', 'score': 0.06962985800565995},\n",
      "                     {'feature': 'doctor', 'score': 0.06779310792572511},\n",
      "                     {'feature': 'pain', 'score': 0.0668010276930299},\n",
      "                     {'feature': 'kidney', 'score': 0.0549079057920354},\n",
      "                     {'feature': 'Kidney', 'score': 0.05326854053175146}]},\n",
      " 2: {'confidence': 0.11115052516607107,\n",
      "     'explanation': [{'feature': 'hp', 'score': -0.0799997479251323},\n",
      "                     {'feature': 'doctor', 'score': -0.04754155417624489},\n",
      "                     {'feature': 'pain', 'score': -0.041227319748901106},\n",
      "                     {'feature': 'kidney', 'score': -0.03950550045278837},\n",
      "                     {'feature': 'Kidney', 'score': -0.03753117417614439}]}}\n"
     ]
    }
   ],
   "source": [
    "exp = explainer.explain_instance(\n",
    "    instance=raw_test.data[7],\n",
    "    labels=[0, 1, 2],\n",
    "    num_features=5\n",
    ")\n",
    "\n",
    "print('Label', raw_train.target_names[raw_test.target[7]], raw_test.target[7])\n",
    "pprint(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i330688/venv_xai/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label soc.religion.christian 2\n",
      "{0: {'confidence': 6.798212345437472e-05,\n",
      "     'explanation': [{'feature': 'Bible', 'score': -0.0023500809763485468},\n",
      "                     {'feature': 'Scripture', 'score': -0.0014344577715211986},\n",
      "                     {'feature': 'Heaven', 'score': -0.001381196356886895},\n",
      "                     {'feature': 'Sin', 'score': -0.0013723724408794883},\n",
      "                     {'feature': 'specific', 'score': -0.0013611914394935848}]},\n",
      " 1: {'confidence': 0.00044272540371258136,\n",
      "     'explanation': [{'feature': 'Bible', 'score': -0.007407412195931125},\n",
      "                     {'feature': 'Scripture', 'score': -0.003658367757678809},\n",
      "                     {'feature': 'Heaven', 'score': -0.003652181996607397},\n",
      "                     {'feature': 'immoral', 'score': -0.003469502264458387},\n",
      "                     {'feature': 'Sin', 'score': -0.003246609821338066}]},\n",
      " 2: {'confidence': 0.9994892924728337,\n",
      "     'explanation': [{'feature': 'Bible', 'score': 0.009736539971486623},\n",
      "                     {'feature': 'Scripture', 'score': 0.005124375636024145},\n",
      "                     {'feature': 'Heaven', 'score': 0.005053514624616295},\n",
      "                     {'feature': 'immoral', 'score': 0.004781252244149238},\n",
      "                     {'feature': 'Sin', 'score': 0.004596128058053568}]}}\n"
     ]
    }
   ],
   "source": [
    "exp = explainer.explain_instance(\n",
    "    instance=raw_test.data[9],\n",
    "    labels=[0, 1, 2],\n",
    "    num_features=5\n",
    ")\n",
    "\n",
    "print('Label', raw_train.target_names[raw_test.target[9]], raw_test.target[9])\n",
    "pprint(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Save and load the explainer\n",
    "\n",
    "Like with the LIME tabular explainer, we can save and load the explainer via `load_explainer` and `save_explainer` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the explainer somewhere\n",
    "\n",
    "explainer.save_explainer('artefacts/lime_text.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i330688/venv_xai/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label soc.religion.christian 2\n",
      "{0: {'confidence': 6.798212345437472e-05,\n",
      "     'explanation': [{'feature': 'Bible', 'score': -0.002291036085092343},\n",
      "                     {'feature': 'Heaven', 'score': -0.001386727909779096},\n",
      "                     {'feature': 'babies', 'score': -0.0013482141842248723},\n",
      "                     {'feature': 'Scripture', 'score': -0.0012967367558917526},\n",
      "                     {'feature': 'infants', 'score': -0.0012887203369136644}]},\n",
      " 1: {'confidence': 0.00044272540371258136,\n",
      "     'explanation': [{'feature': 'Bible', 'score': -0.007441841401906927},\n",
      "                     {'feature': 'Heaven', 'score': -0.003699731572404996},\n",
      "                     {'feature': 'Scripture', 'score': -0.003493032440072657},\n",
      "                     {'feature': 'God', 'score': -0.0030701936621817727},\n",
      "                     {'feature': 'doctrine', 'score': -0.003026287136219051}]},\n",
      " 2: {'confidence': 0.9994892924728337,\n",
      "     'explanation': [{'feature': 'Bible', 'score': 0.009764693171821786},\n",
      "                     {'feature': 'Heaven', 'score': 0.0051058553475867505},\n",
      "                     {'feature': 'Scripture', 'score': 0.00481801754635917},\n",
      "                     {'feature': 'God', 'score': 0.004325649143393945},\n",
      "                     {'feature': 'doctrine', 'score': 0.00424415351934624}]}}\n"
     ]
    }
   ],
   "source": [
    "# Load the saved explainer in a new Explainer instance\n",
    "\n",
    "new_explainer = ExplainerFactory.get_explainer(domain=xai.DOMAIN.TEXT, algorithm=xai.ALG.LIME)\n",
    "new_explainer.load_explainer('artefacts/lime_text.pkl')\n",
    "\n",
    "exp = new_explainer.explain_instance(\n",
    "    instance=raw_test.data[9],\n",
    "    labels=[0, 1, 2],\n",
    "    num_features=5\n",
    ")\n",
    "\n",
    "print('Label', raw_train.target_names[raw_test.target[9]], raw_test.target[9])\n",
    "pprint(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
