{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP Kernel Explainer for Tabular Data via XAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i330688/venv_xai/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/i330688/venv_xai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Some auxiliary imports for the tutorial\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import shap\n",
    "import os\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(123456)\n",
    "\n",
    "# Set the path so that we can import the Explainer\n",
    "sys.path.append('../../')\n",
    "\n",
    "# Main XAI imports\n",
    "import xai\n",
    "from xai.explainer import Explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train a model on a sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset and prepare training and test sets\n",
    "raw_data = datasets.load_breast_cancer()\n",
    "X, y = raw_data['data'], raw_data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate a classifier, train, and evaluate on test set\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Instantiate the explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate LimeTabularExplainer via the Explainer interface\n",
    "explainer = Explainer(domain=xai.DOMAIN.TABULAR, algorithm=xai.ALG.SHAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build the explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 455 background data samples could cause slower run times. Consider using shap.kmeans(data, K) to summarize the background as K weighted samples.\n"
     ]
    }
   ],
   "source": [
    "explainer.build_explainer(\n",
    "    predict_fn=clf.predict_proba,\n",
    "    data=X_train,\n",
    "    feature_names=raw_data['feature_names']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Generate some explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975c087b8975468bb2f5dfcfe9e8250e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{0: {'confidence': 0.0,\n",
      "     'explanation': [{'feature': 'mean texture = 11.97',\n",
      "                      'score': -0.05706698133719296},\n",
      "                     {'feature': 'mean area = 288.5',\n",
      "                      'score': -0.0599174206393038},\n",
      "                     {'feature': 'worst radius = 10.62',\n",
      "                      'score': -0.06305883115185068},\n",
      "                     {'feature': 'worst perimeter = 66.53',\n",
      "                      'score': -0.10051281591924938},\n",
      "                     {'feature': 'worst area = 342.9',\n",
      "                      'score': -0.08911428062273208}]},\n",
      " 1: {'confidence': 1.0,\n",
      "     'explanation': [{'feature': 'mean texture = 11.97',\n",
      "                      'score': 0.05706698133719329},\n",
      "                     {'feature': 'mean area = 288.5',\n",
      "                      'score': 0.059917420639304386},\n",
      "                     {'feature': 'worst radius = 10.62',\n",
      "                      'score': 0.06305883115185107},\n",
      "                     {'feature': 'worst perimeter = 66.53',\n",
      "                      'score': 0.10051281591925004},\n",
      "                     {'feature': 'worst area = 342.9',\n",
      "                      'score': 0.08911428062273263}]}}\n"
     ]
    }
   ],
   "source": [
    "exp = explainer.explain_instance(\n",
    "    instance=X_test[0],\n",
    "    nsamples=None,\n",
    "    num_features=10\n",
    ")\n",
    "\n",
    "pprint(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Save and load the explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the explainer somewhere\n",
    "\n",
    "explainer.save_explainer('artefacts/shap_tabular.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21000ccc6d8414ca7ea5dc7af1b3b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{0: {'confidence': 0.0,\n",
      "     'explanation': [{'feature': 'mean texture = 11.97',\n",
      "                      'score': -0.05276770912762013},\n",
      "                     {'feature': 'mean area = 288.5',\n",
      "                      'score': -0.06534141817645864},\n",
      "                     {'feature': 'worst radius = 10.62',\n",
      "                      'score': -0.062258506620849946},\n",
      "                     {'feature': 'worst perimeter = 66.53',\n",
      "                      'score': -0.09469370474349056},\n",
      "                     {'feature': 'worst area = 342.9',\n",
      "                      'score': -0.09460899100190961}]},\n",
      " 1: {'confidence': 1.0,\n",
      "     'explanation': [{'feature': 'mean texture = 11.97',\n",
      "                      'score': 0.05276770912762074},\n",
      "                     {'feature': 'mean area = 288.5',\n",
      "                      'score': 0.06534141817645922},\n",
      "                     {'feature': 'worst radius = 10.62',\n",
      "                      'score': 0.06225850662085014},\n",
      "                     {'feature': 'worst perimeter = 66.53',\n",
      "                      'score': 0.09469370474349109},\n",
      "                     {'feature': 'worst area = 342.9',\n",
      "                      'score': 0.0946089910019102}]}}\n"
     ]
    }
   ],
   "source": [
    "# Load the saved explainer in a new Explainer instance\n",
    "\n",
    "new_explainer = Explainer(domain=xai.DOMAIN.TABULAR, algorithm=xai.ALG.SHAP)\n",
    "new_explainer.load_explainer('artefacts/shap_tabular.pkl')\n",
    "\n",
    "exp = new_explainer.explain_instance(\n",
    "    instance=X_test[0],\n",
    "    nsamples=None,\n",
    "    num_features=10\n",
    ")\n",
    "\n",
    "pprint(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('artefacts/shap_tabular.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
